{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zoVtFSgh21wE"
      ],
      "authorship_tag": "ABX9TyNL28g24L65e4puPpLNjET4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CP2J/cp2j/blob/ACJ-9-MF-SGD-/mf_sgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-4VKCeENpw-2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#rating = pd.read_csv('/content/drive/MyDrive/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CkMxfW6tNVH",
        "outputId": "b1504741-cee6-4ada-cf35-e7a1b22585bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 읽어 오기 \n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/ml-100k/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
        "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거"
      ],
      "metadata": {
        "id": "wgDyHUCCtUH2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # train test 분리\n",
        "# from sklearn.utils import shuffle\n",
        "# TRAIN_SIZE = 0.75\n",
        "# ratings = shuffle(ratings, random_state=1)\n",
        "# cutoff = int(TRAIN_SIZE * len(ratings))\n",
        "# ratings_train = ratings.iloc[:cutoff]\n",
        "# ratings_test = ratings.iloc[cutoff:]"
      ],
      "metadata": {
        "id": "5DpxnLgntbsJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test 분리\n",
        "# Rating df의 user_id를 타겟(종속변수, 예측값)으로 train, test stratified split 실시(user_id 기준)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x = ratings.copy()\n",
        "y = ratings['user_id']\n",
        "ratings_train, ratings_test = train_test_split(x, test_size=0.25, stratify=y, random_state=12)"
      ],
      "metadata": {
        "id": "EjMKTNAEb4pz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도(RMSE)를 계산하는 함수 \n",
        "def RMSE(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))"
      ],
      "metadata": {
        "id": "QkJKXYgdxYl7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MF-SGD"
      ],
      "metadata": {
        "id": "1NWGs_Nf26QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### MF-SGD 추천 알고리즘 >>>>>>>>>>>>>>>\n",
        "class NEW_MF():\n",
        "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):  # 클래스 생성시 실행되는 초기화 함수\n",
        "        self.R = np.array(ratings)    # df ratings를 np.array로 바꿔 self.R에 저장\n",
        "\n",
        "        item_id_index = []    # 변수 초기화\n",
        "        index_item_id = []    # 변수 초기화\n",
        "        for i, one_id in enumerate(ratings):        # df ratings의 각 items에 대해서 아래 작업 수행\n",
        "            item_id_index.append([one_id, i])       # save id - index \n",
        "            index_item_id.append([i, one_id])       # save index - id\n",
        "        self.item_id_index = dict(item_id_index)    # dict로 변환\n",
        "        self.index_item_id = dict(index_item_id)    # dict로 변환\n",
        "\n",
        "        user_id_index = []                          # 사용자에 대해서도 실행\n",
        "        index_user_id = []\n",
        "        for i, one_id in enumerate(ratings.T):\n",
        "            user_id_index.append([one_id, i])\n",
        "            index_user_id.append([i, one_id])\n",
        "        self.user_id_index = dict(user_id_index)    # dict로 변환\n",
        "        self.index_user_id = dict(index_user_id)\n",
        "\n",
        "        self.num_users, self.num_items = np.shape(self.R)\n",
        "        self.K = K                                  # 잠재요인 수\n",
        "        self.alpha = alpha                          # 학습률\n",
        "        self.beta = beta                            # 정규화계수\n",
        "        self.iterations = iterations                # SGD 계산 반복 횟수\n",
        "        self.verbose = verbose                      # 중간 학습과정 출력여부\n",
        "\n",
        "    # train set의 RMSE 계산\n",
        "    def rmse(self):                            # 현재 P,Q로 RMSE 계산\n",
        "        xs, ys = self.R.nonzero()              # R에서 평점이 있는(NOT NULL) 요소의 인덱스들\n",
        "        self.predictions = []\n",
        "        self.errors = []\n",
        "        for x, y in zip(xs, ys):                            # 평점이 있는 요소(사용자 x, 아이템 y)에 대해:\n",
        "            prediction = self.get_prediction(x, y)\n",
        "            self.predictions.append(prediction)             # 예측값을 예측리스트에,\n",
        "            self.errors.append(self.R[x, y] - prediction)   # 오차를 오차리스트에 저장\n",
        "        self.predictions = np.array(self.predictions)\n",
        "        self.errors = np.array(self.errors)\n",
        "        return np.sqrt(np.mean(self.errors**2))\n",
        "\n",
        "    # Predict Ratings for user i and item j\n",
        "    def get_prediction(self, i, j):\n",
        "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)    # 평점 예측치(r^)의 식에 사용자, 아이템 편향 추가한 식\n",
        "        # b : 전체평균, b_u[i] : 사용자i 평가경향(bias), b_d[j] : 아이템j 평가경향, 넷째항 : P, Q.T를 내적한 예측평점\n",
        "        return prediction\n",
        "\n",
        "    # Stochastic gradient descent to get optimized P and Q matrix\n",
        "    def sgd(self):\n",
        "        for i, j, r in self.samples:                # samples의 (user-item-rating) set에 대해 sgd적용\n",
        "            prediction = self.get_prediction(i, j)\n",
        "            e = (r - prediction)                    # 오차 = 실제평점 - 예측\n",
        "\n",
        "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])     # 사용자,아이템의 경향성을 고려된 평점예측식의 편미분식으로 사용자 평가경향 업데이트\n",
        "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])     # 아이템 평가경향 업데이트\n",
        "\n",
        "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])   # 정규화항 추가된 평점예측식의 편미분식으로 P행렬 업뎃\n",
        "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])   # Q 업뎃\n",
        "\n",
        "    # Test set을 선정 - 분리된 test set을 넘겨받아서 클래스 내부의 test set을 만드는 함수\n",
        "    def set_test(self, ratings_test):\n",
        "        test_set = []\n",
        "        for i in range(len(ratings_test)):\n",
        "            x = self.user_id_index[ratings_test.iloc[i, 0]]   # 현재 사용자의 인덱스를 user_id_index(매핑 리스트)에서 받아옴\n",
        "            y = self.item_id_index[ratings_test.iloc[i, 1]]   # 현재 아이템의 인덱스를 item_id_index(매핑 리스트)에서 받아옴\n",
        "            z = ratings_test.iloc[i, 2]                       # 현재 (사용자-아이템)의 평점\n",
        "            test_set.append([x, y, z])          # 현재 (사용자-아이템-평점)을 test_set에 추가\n",
        "            self.R[x, y] = 0                    # Setting test set ratings to 0 : MF는 R 전체를 사용해서 학습하기 때문에 test set은 평점을 지움\n",
        "        self.test_set = test_set                # test_set을 클래스에 저장한다.\n",
        "        return test_set                         # Return test set\n",
        "\n",
        "    # Test set의 RMSE 계산\n",
        "    def test_rmse(self):\n",
        "        error = 0\n",
        "        for one_set in self.test_set:\n",
        "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
        "            error += pow(one_set[2] - predicted, 2)       # 오차(평점 실제값 - 예측평점)의 제곱을 누적한 값이 저장된다.\n",
        "        return np.sqrt(error/len(self.test_set))          # error를 RMSE로 변환해서 돌려준다.\n",
        "\n",
        "    # Training 하면서 test set의 정확도를 계산\n",
        "    def test(self):   # MF모델을 SGD방식으로 훈련하는 핵심 함수이다.\n",
        "        # Initializing user-feature and item-feature matrix\n",
        "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))   # P행렬을 (평균 0, 표준편차 1/K인 정규분포 난수)로 초기화한다.\n",
        "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))   # Q행렬 초기화한다.\n",
        "\n",
        "        # Initializing the bias terms\n",
        "        self.b_u = np.zeros(self.num_users)           # 사용자 평가경향을 초기화, array크기는 사용자수(num_users)와 동일하다.\n",
        "        self.b_d = np.zeros(self.num_items)           # 아이템 평가경향을 초기화한다.\n",
        "        self.b = np.mean(self.R[self.R.nonzero()])    # 전체 평균을 구해서 저장한다.\n",
        "\n",
        "        # List of training samples\n",
        "        rows, columns = self.R.nonzero()              # 평점행렬 R 중에서 평점있는 요소의 인덱스를 가져온다.\n",
        "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]   \n",
        "        # SGD를 적용할 대상, 즉 평점이 있는 요소의 인덱스와 평점을 리스트로 만들어 samples에 저장한다.\n",
        "\n",
        "        # Stochastic gradient descent for given number of iterations\n",
        "        training_process = []                             # training_process 를 초기화한다. SGD를 한번 실행할 때마다 RMSE가 얼마나 개선되는지를 기록한다.\n",
        "        for i in range(self.iterations):                  # 지정된 반복 횟수만큼 SGD를 실행한다.\n",
        "            np.random.shuffle(self.samples)               # samples 를 임의로 섞는다. 출발점에 따라 수렴의 속도가 달라질 수 있기 때문이다.\n",
        "            self.sgd()                                    # SGD를 실행하는 함수를 호출한다.\n",
        "            rmse1 = self.rmse()                           # SGD로 P, Q, bu, bd가 업데이트 되었으므로 이에 따른 RMSE를 계산한다.\n",
        "            rmse2 = self.test_rmse()                      # test set은 별도로 계산한다.\n",
        "            training_process.append((i+1, rmse1, rmse2))  # 결과를 저장한다.\n",
        "            if self.verbose:                              # verbose가 True이면 10회 반복마다 중간 결과를 표시한다.\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
        "        return training_process\n",
        "\n",
        "    # Ratings for given user_id and item_id\n",
        "    def get_one_prediction(self, user_id, item_id):\n",
        "        prediction = self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
        "        return prediction\n",
        "\n",
        "    # Full user-movie rating matrix (모든 사용자의 모든 아이템에 대한 예측치(Full matrix)를 계산해서 돌려준다)\n",
        "    def full_prediction(self):\n",
        "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n",
        "        # $\\hat{r}_{ij}=b+bu_i+bd_j+\\sum_{k=1}^Kp_{ik}q_{kj}$\n"
      ],
      "metadata": {
        "id": "kyRxSHB4CLKq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MF클래스 생성 및 학습\n",
        "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)    # 전체 데이터를 full matrix로 변환한다.\n",
        "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=400, verbose=True)          # NEW-MF 클래스를 생성한다.\n",
        "test_set = mf.set_test(ratings_test)    # ratings_test를 테스트 데이터로 지정하도록 set_test() 함수를 호출한다.\n",
        "result = mf.test()                      # 정해진 파라미터에 따라 MF 훈련과 정확도 계산을 실행한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwrF4tqY70R1",
        "outputId": "8fca5463-12c8-4551-abef-083df498edbc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9777\n",
            "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9584\n",
            "Iteration: 30 ; Train RMSE = 0.9328 ; Test RMSE = 0.9507\n",
            "Iteration: 40 ; Train RMSE = 0.9265 ; Test RMSE = 0.9467\n",
            "Iteration: 50 ; Train RMSE = 0.9225 ; Test RMSE = 0.9444\n",
            "Iteration: 60 ; Train RMSE = 0.9197 ; Test RMSE = 0.9430\n",
            "Iteration: 70 ; Train RMSE = 0.9175 ; Test RMSE = 0.9420\n",
            "Iteration: 80 ; Train RMSE = 0.9156 ; Test RMSE = 0.9414\n",
            "Iteration: 90 ; Train RMSE = 0.9138 ; Test RMSE = 0.9408\n",
            "Iteration: 100 ; Train RMSE = 0.9119 ; Test RMSE = 0.9402\n",
            "Iteration: 110 ; Train RMSE = 0.9095 ; Test RMSE = 0.9395\n",
            "Iteration: 120 ; Train RMSE = 0.9062 ; Test RMSE = 0.9384\n",
            "Iteration: 130 ; Train RMSE = 0.9015 ; Test RMSE = 0.9367\n",
            "Iteration: 140 ; Train RMSE = 0.8949 ; Test RMSE = 0.9343\n",
            "Iteration: 150 ; Train RMSE = 0.8862 ; Test RMSE = 0.9312\n",
            "Iteration: 160 ; Train RMSE = 0.8756 ; Test RMSE = 0.9277\n",
            "Iteration: 170 ; Train RMSE = 0.8636 ; Test RMSE = 0.9244\n",
            "Iteration: 180 ; Train RMSE = 0.8502 ; Test RMSE = 0.9213\n",
            "Iteration: 190 ; Train RMSE = 0.8355 ; Test RMSE = 0.9184\n",
            "Iteration: 200 ; Train RMSE = 0.8193 ; Test RMSE = 0.9158\n",
            "Iteration: 210 ; Train RMSE = 0.8014 ; Test RMSE = 0.9134\n",
            "Iteration: 220 ; Train RMSE = 0.7820 ; Test RMSE = 0.9113\n",
            "Iteration: 230 ; Train RMSE = 0.7611 ; Test RMSE = 0.9096\n",
            "Iteration: 240 ; Train RMSE = 0.7389 ; Test RMSE = 0.9084\n",
            "Iteration: 250 ; Train RMSE = 0.7159 ; Test RMSE = 0.9077\n",
            "Iteration: 260 ; Train RMSE = 0.6921 ; Test RMSE = 0.9075\n",
            "Iteration: 270 ; Train RMSE = 0.6680 ; Test RMSE = 0.9078\n",
            "Iteration: 280 ; Train RMSE = 0.6438 ; Test RMSE = 0.9085\n",
            "Iteration: 290 ; Train RMSE = 0.6198 ; Test RMSE = 0.9096\n",
            "Iteration: 300 ; Train RMSE = 0.5960 ; Test RMSE = 0.9110\n",
            "Iteration: 310 ; Train RMSE = 0.5728 ; Test RMSE = 0.9127\n",
            "Iteration: 320 ; Train RMSE = 0.5501 ; Test RMSE = 0.9145\n",
            "Iteration: 330 ; Train RMSE = 0.5283 ; Test RMSE = 0.9164\n",
            "Iteration: 340 ; Train RMSE = 0.5072 ; Test RMSE = 0.9184\n",
            "Iteration: 350 ; Train RMSE = 0.4870 ; Test RMSE = 0.9203\n",
            "Iteration: 360 ; Train RMSE = 0.4678 ; Test RMSE = 0.9223\n",
            "Iteration: 370 ; Train RMSE = 0.4495 ; Test RMSE = 0.9243\n",
            "Iteration: 380 ; Train RMSE = 0.4321 ; Test RMSE = 0.9262\n",
            "Iteration: 390 ; Train RMSE = 0.4156 ; Test RMSE = 0.9280\n",
            "Iteration: 400 ; Train RMSE = 0.4000 ; Test RMSE = 0.9298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iteration = 200\n",
        "# learning_rate = 0.01\n",
        "# lmbda = 0.01"
      ],
      "metadata": {
        "id": "ub7JfffC3ck5"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}