{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zoVtFSgh21wE"
      ],
      "authorship_tag": "ABX9TyO/erxyD1ySUI4R+4QP77dS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CP2J/cp2j/blob/ACJ-14-Hybrid_Model/RecSys_Hybrid_(MF-DL).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 하이브리드 추천시스템 (MF_SGD + DL)"
      ],
      "metadata": {
        "id": "BvWwCwyQsmKG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-4VKCeENpw-2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#rating = pd.read_csv('/content/drive/MyDrive/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CkMxfW6tNVH",
        "outputId": "3425a50e-0a63-42c0-ce3b-ffb14c8e4e48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 읽어 오기 \n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/ml-100k/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
        "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거"
      ],
      "metadata": {
        "id": "wgDyHUCCtUH2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test 분리\n",
        "from sklearn.utils import shuffle\n",
        "TRAIN_SIZE = 0.75\n",
        "ratings = shuffle(ratings, random_state=1)\n",
        "cutoff = int(TRAIN_SIZE * len(ratings))\n",
        "ratings_train = ratings.iloc[:cutoff]\n",
        "ratings_test = ratings.iloc[cutoff:]"
      ],
      "metadata": {
        "id": "5DpxnLgntbsJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도(RMSE)를 계산하는 함수 \n",
        "def RMSE(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))"
      ],
      "metadata": {
        "id": "QkJKXYgdxYl7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MF-SGD"
      ],
      "metadata": {
        "id": "1NWGs_Nf26QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### MF-SGD 추천 알고리즘 >>>>>>>>>>>>>>>\n",
        "class NEW_MF():\n",
        "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):  # 클래스 생성시 실행되는 초기화 함수\n",
        "        self.R = np.array(ratings)    # df ratings를 np.array로 바꿔 self.R에 저장\n",
        "\n",
        "        item_id_index = []    # 변수 초기화\n",
        "        index_item_id = []    # 변수 초기화\n",
        "        for i, one_id in enumerate(ratings):        # df ratings의 각 items에 대해서 아래 작업 수행\n",
        "            item_id_index.append([one_id, i])       # save id - index \n",
        "            index_item_id.append([i, one_id])       # save index - id\n",
        "        self.item_id_index = dict(item_id_index)    # dict로 변환\n",
        "        self.index_item_id = dict(index_item_id)    # dict로 변환\n",
        "\n",
        "        user_id_index = []                          # 사용자에 대해서도 실행\n",
        "        index_user_id = []\n",
        "        for i, one_id in enumerate(ratings.T):\n",
        "            user_id_index.append([one_id, i])\n",
        "            index_user_id.append([i, one_id])\n",
        "        self.user_id_index = dict(user_id_index)    # dict로 변환\n",
        "        self.index_user_id = dict(index_user_id)\n",
        "\n",
        "        self.num_users, self.num_items = np.shape(self.R)\n",
        "        self.K = K                                  # 잠재요인 수\n",
        "        self.alpha = alpha                          # 학습률\n",
        "        self.beta = beta                            # 정규화계수\n",
        "        self.iterations = iterations                # SGD 계산 반복 횟수\n",
        "        self.verbose = verbose                      # 중간 학습과정 출력여부\n",
        "\n",
        "    # train set의 RMSE 계산\n",
        "    def rmse(self):                            # 현재 P,Q로 RMSE 계산\n",
        "        xs, ys = self.R.nonzero()              # R에서 평점이 있는(NOT NULL) 요소의 인덱스들\n",
        "        self.predictions = []\n",
        "        self.errors = []\n",
        "        for x, y in zip(xs, ys):                            # 평점이 있는 요소(사용자 x, 아이템 y)에 대해:\n",
        "            prediction = self.get_prediction(x, y)\n",
        "            self.predictions.append(prediction)             # 예측값을 예측리스트에,\n",
        "            self.errors.append(self.R[x, y] - prediction)   # 오차를 오차리스트에 저장\n",
        "        self.predictions = np.array(self.predictions)\n",
        "        self.errors = np.array(self.errors)\n",
        "        return np.sqrt(np.mean(self.errors**2))\n",
        "\n",
        "    # Predict Ratings for user i and item j\n",
        "    def get_prediction(self, i, j):\n",
        "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)    # 평점 예측치(r^)의 식에 사용자, 아이템 편향 추가한 식\n",
        "        # b : 전체평균, b_u[i] : 사용자i 평가경향(bias), b_d[j] : 아이템j 평가경향, 넷째항 : P, Q.T를 내적한 예측평점\n",
        "        return prediction\n",
        "\n",
        "    # Stochastic gradient descent to get optimized P and Q matrix\n",
        "    def sgd(self):\n",
        "        for i, j, r in self.samples:                # samples의 (user-item-rating) set에 대해 sgd적용\n",
        "            prediction = self.get_prediction(i, j)\n",
        "            e = (r - prediction)                    # 오차 = 실제평점 - 예측\n",
        "\n",
        "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])     # 사용자,아이템의 경향성을 고려된 평점예측식의 편미분식으로 사용자 평가경향 업데이트\n",
        "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])     # 아이템 평가경향 업데이트\n",
        "\n",
        "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])   # 정규화항 추가된 평점예측식의 편미분식으로 P행렬 업뎃\n",
        "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])   # Q 업뎃\n",
        "\n",
        "    # Test set을 선정 - 분리된 test set을 넘겨받아서 클래스 내부의 test set을 만드는 함수\n",
        "    def set_test(self, ratings_test):\n",
        "        test_set = []\n",
        "        for i in range(len(ratings_test)):\n",
        "            x = self.user_id_index[ratings_test.iloc[i, 0]]   # 현재 사용자의 인덱스를 user_id_index(매핑 리스트)에서 받아옴\n",
        "            y = self.item_id_index[ratings_test.iloc[i, 1]]   # 현재 아이템의 인덱스를 item_id_index(매핑 리스트)에서 받아옴\n",
        "            z = ratings_test.iloc[i, 2]                       # 현재 (사용자-아이템)의 평점\n",
        "            test_set.append([x, y, z])          # 현재 (사용자-아이템-평점)을 test_set에 추가\n",
        "            self.R[x, y] = 0                    # Setting test set ratings to 0 : MF는 R 전체를 사용해서 학습하기 때문에 test set은 평점을 지움\n",
        "        self.test_set = test_set                # test_set을 클래스에 저장한다.\n",
        "        return test_set                         # Return test set\n",
        "\n",
        "    # Test set의 RMSE 계산\n",
        "    def test_rmse(self):\n",
        "        error = 0\n",
        "        for one_set in self.test_set:\n",
        "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
        "            error += pow(one_set[2] - predicted, 2)       # 오차(평점 실제값 - 예측평점)의 제곱을 누적한 값이 저장된다.\n",
        "        return np.sqrt(error/len(self.test_set))          # error를 RMSE로 변환해서 돌려준다.\n",
        "\n",
        "    # Training 하면서 test set의 정확도를 계산\n",
        "    def test(self):   # MF모델을 SGD방식으로 훈련하는 핵심 함수이다.\n",
        "        # Initializing user-feature and item-feature matrix\n",
        "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))   # P행렬을 (평균 0, 표준편차 1/K인 정규분포 난수)로 초기화한다.\n",
        "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))   # Q행렬 초기화한다.\n",
        "\n",
        "        # Initializing the bias terms\n",
        "        self.b_u = np.zeros(self.num_users)           # 사용자 평가경향을 초기화, array크기는 사용자수(num_users)와 동일하다.\n",
        "        self.b_d = np.zeros(self.num_items)           # 아이템 평가경향을 초기화한다.\n",
        "        self.b = np.mean(self.R[self.R.nonzero()])    # 전체 평균을 구해서 저장한다.\n",
        "\n",
        "        # List of training samples\n",
        "        rows, columns = self.R.nonzero()              # 평점행렬 R 중에서 평점있는 요소의 인덱스를 가져온다.\n",
        "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]   \n",
        "        # SGD를 적용할 대상, 즉 평점이 있는 요소의 인덱스와 평점을 리스트로 만들어 samples에 저장한다.\n",
        "\n",
        "        # Stochastic gradient descent for given number of iterations\n",
        "        training_process = []                             # training_process 를 초기화한다. SGD를 한번 실행할 때마다 RMSE가 얼마나 개선되는지를 기록한다.\n",
        "        for i in range(self.iterations):                  # 지정된 반복 횟수만큼 SGD를 실행한다.\n",
        "            np.random.shuffle(self.samples)               # samples 를 임의로 섞는다. 출발점에 따라 수렴의 속도가 달라질 수 있기 때문이다.\n",
        "            self.sgd()                                    # SGD를 실행하는 함수를 호출한다.\n",
        "            rmse1 = self.rmse()                           # SGD로 P, Q, bu, bd가 업데이트 되었으므로 이에 따른 RMSE를 계산한다.\n",
        "            rmse2 = self.test_rmse()                      # test set은 별도로 계산한다.\n",
        "            training_process.append((i+1, rmse1, rmse2))  # 결과를 저장한다.\n",
        "            if self.verbose:                              # verbose가 True이면 10회 반복마다 중간 결과를 표시한다.\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
        "        return training_process\n",
        "\n",
        "    # Ratings for given user_id and item_id\n",
        "    def get_one_prediction(self, user_id, item_id):\n",
        "        prediction = self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
        "        return prediction\n",
        "\n",
        "    # Full user-movie rating matrix (모든 사용자의 모든 아이템에 대한 예측치(Full matrix)를 계산해서 돌려준다)\n",
        "    def full_prediction(self):\n",
        "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n",
        "        # $\\hat{r}_{ij}=b+bu_i+bd_j+\\sum_{k=1}^Kp_{ik}q_{kj}$\n"
      ],
      "metadata": {
        "id": "kyRxSHB4CLKq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MF클래스 생성 및 학습\n",
        "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)    # 전체 데이터를 full matrix로 변환한다.\n",
        "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=300, verbose=True)          # NEW-MF 클래스를 생성한다.\n",
        "test_set = mf.set_test(ratings_test)    # ratings_test를 테스트 데이터로 지정하도록 set_test() 함수를 호출한다.\n",
        "result = mf.test()                      # 정해진 파라미터에 따라 MF 훈련과 정확도 계산을 실행한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwrF4tqY70R1",
        "outputId": "0029a21b-c38d-4ed4-85f1-8ae783618b31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
            "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
            "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
            "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9523\n",
            "Iteration: 50 ; Train RMSE = 0.9214 ; Test RMSE = 0.9497\n",
            "Iteration: 60 ; Train RMSE = 0.9186 ; Test RMSE = 0.9480\n",
            "Iteration: 70 ; Train RMSE = 0.9165 ; Test RMSE = 0.9468\n",
            "Iteration: 80 ; Train RMSE = 0.9147 ; Test RMSE = 0.9459\n",
            "Iteration: 90 ; Train RMSE = 0.9130 ; Test RMSE = 0.9451\n",
            "Iteration: 100 ; Train RMSE = 0.9111 ; Test RMSE = 0.9444\n",
            "Iteration: 110 ; Train RMSE = 0.9088 ; Test RMSE = 0.9435\n",
            "Iteration: 120 ; Train RMSE = 0.9056 ; Test RMSE = 0.9423\n",
            "Iteration: 130 ; Train RMSE = 0.9010 ; Test RMSE = 0.9405\n",
            "Iteration: 140 ; Train RMSE = 0.8945 ; Test RMSE = 0.9380\n",
            "Iteration: 150 ; Train RMSE = 0.8859 ; Test RMSE = 0.9348\n",
            "Iteration: 160 ; Train RMSE = 0.8753 ; Test RMSE = 0.9312\n",
            "Iteration: 170 ; Train RMSE = 0.8630 ; Test RMSE = 0.9276\n",
            "Iteration: 180 ; Train RMSE = 0.8494 ; Test RMSE = 0.9242\n",
            "Iteration: 190 ; Train RMSE = 0.8345 ; Test RMSE = 0.9211\n",
            "Iteration: 200 ; Train RMSE = 0.8179 ; Test RMSE = 0.9183\n",
            "Iteration: 210 ; Train RMSE = 0.7998 ; Test RMSE = 0.9159\n",
            "Iteration: 220 ; Train RMSE = 0.7799 ; Test RMSE = 0.9138\n",
            "Iteration: 230 ; Train RMSE = 0.7585 ; Test RMSE = 0.9122\n",
            "Iteration: 240 ; Train RMSE = 0.7359 ; Test RMSE = 0.9112\n",
            "Iteration: 250 ; Train RMSE = 0.7124 ; Test RMSE = 0.9107\n",
            "Iteration: 260 ; Train RMSE = 0.6883 ; Test RMSE = 0.9108\n",
            "Iteration: 270 ; Train RMSE = 0.6640 ; Test RMSE = 0.9115\n",
            "Iteration: 280 ; Train RMSE = 0.6397 ; Test RMSE = 0.9125\n",
            "Iteration: 290 ; Train RMSE = 0.6158 ; Test RMSE = 0.9140\n",
            "Iteration: 300 ; Train RMSE = 0.5922 ; Test RMSE = 0.9157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL"
      ],
      "metadata": {
        "id": "2Fn_1Uh0MXNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### (1)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD, Adamax"
      ],
      "metadata": {
        "id": "8tgw3_ikMWll"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable 초기화\n",
        "K = 200                               # Latent factor(잠재요인) 수\n",
        "mu = ratings_train.rating.mean()      # 전체 평균\n",
        "M = ratings.user_id.max() +1          # 사용자 아이디 최대값+1 : Number of users로 간주, 추후 Embedding에 사용\n",
        "# 사용자 아이디는 1부터 943이지만(위 describe 참고)\n",
        "# adding 1 ensures that all user IDs from 0 to the maximum ID are included in the embedding layer.\n",
        "N = ratings.movie_id.max() +1         # Number of movies\n",
        "\n",
        "# RMSE 정의\n",
        "def RMSE(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
      ],
      "metadata": {
        "id": "B880jNpHNmK0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### (2)\n",
        "# Keras model\n",
        "user = Input(shape=(1, ))                                             # 사용자 데이터 입력 형식 지정(id만 받음)\n",
        "item = Input(shape=(1, ))                                             # 아이템 데이터 입력 형식 지정(id만 받음)\n",
        "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)      # 사용자 Embedding layer 지정 (M, 1, K) : (M X K)의 연결을 가진다.\n",
        "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)      # 아이템 Embedding layer 지정 (N, 1, K) : (N X K)의 연결을 가진다.\n",
        "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)        # User bias term (M, 1, ) : (M X 1)의 연결\n",
        "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)        # Item bias term (N, 1, ) : (N X 1)의 연결\n",
        "\n",
        "# Concatenate layers\n",
        "from tensorflow.keras.layers import Dense, Concatenate, Activation    # 나중에 layer 구성에서 사용할 메소드 로드\n",
        "P_embedding = Flatten()(P_embedding)          # (K, )\n",
        "Q_embedding = Flatten()(Q_embedding)          # (K, )\n",
        "user_bias = Flatten()(user_bias)              # (1, )\n",
        "item_bias = Flatten()(item_bias)              # (1, )\n",
        "# Concatenate() 위해서 1차원으로 줄인다.\n",
        "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])   # (2K+2, )\n",
        "# P, Q, 사용자 bias, 아이템 bias를 붙여서 하나의 layer를 만든다.\n",
        "\n",
        "# Neural network\n",
        "R = Dense(2048)(R)              # 노드가 2048개인 dense layer 추가\n",
        "R = Activation('relu')(R)       # 이 layer의 activation 함수 : 'relu'\n",
        "R = Dense(256)(R)               # 노드가 256개인 dense layer 하나 더 추가\n",
        "R = Activation('linear')(R)     # 이 layer의 activation 함수 : 'linear'\n",
        "R = Dense(1)(R)                 # 노드가 1개인 dense layer를 하나 더 추가 한다. 이 layer가 출력에 연결된다.\n",
        "\n",
        "# Model setting : 위의 신경망과 입력을 연결해서 모델을 구성한다.\n",
        "model = Model(inputs = [user, item], outputs = R)\n",
        "model.compile(\n",
        "    loss = RMSE,                # loss함수\n",
        "    optimizer = SGD(),\n",
        "    #optimizer = Adamax(),\n",
        "    metrics = [RMSE]            # 측정지표\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7Xtk3JPsN5Aj",
        "outputId": "219ec9ac-5668-411b-e5d7-59e55cddf603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 200)       188800      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 200)       336600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 1, 1)         944         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 1, 1)         1683        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 200)          0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 200)          0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1)            0           ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 1)            0           ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 402)          0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]',              \n",
            "                                                                  'flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2048)         825344      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 2048)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          524544      ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            257         ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,878,172\n",
            "Trainable params: 1,878,172\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fitting (위에서 구성한 신경망을 학습시킨다)\n",
        "result = model.fit(\n",
        "    x = [ratings_train.user_id.values, ratings_train.movie_id.values],\n",
        "    # 입력(독립변수)은 train set의 사용자, 아이템 id\n",
        "    y = ratings_train.rating.values - mu,\n",
        "    # 출력(종속변수)은 평점에서 전체평균을 뺀 것으로 지정\n",
        "    epochs = 65,              # 반복횟수\n",
        "    batch_size = 512,         # 한번에 학습(연산)하는 batch 크기를 지정\n",
        "    validation_data = (\n",
        "      [ratings_test.user_id.values, ratings_test.movie_id.values],  # 검증을 위한 입력\n",
        "      ratings_test.rating.values - mu                               # 검증에 쓰이는 출력\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "NjOcJ49HN7O5",
        "outputId": "78a46094-5032-4aab-8c03-a04ade1784b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/65\n",
            "147/147 [==============================] - 7s 9ms/step - loss: 5.3960 - RMSE: 1.1254 - val_loss: 5.2705 - val_RMSE: 1.1251\n",
            "Epoch 2/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 5.1512 - RMSE: 1.1244 - val_loss: 5.0329 - val_RMSE: 1.1243\n",
            "Epoch 3/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 4.9202 - RMSE: 1.1232 - val_loss: 4.8090 - val_RMSE: 1.1235\n",
            "Epoch 4/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 4.7026 - RMSE: 1.1224 - val_loss: 4.5977 - val_RMSE: 1.1227\n",
            "Epoch 5/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 4.4973 - RMSE: 1.1216 - val_loss: 4.3986 - val_RMSE: 1.1220\n",
            "Epoch 6/65\n",
            "147/147 [==============================] - 1s 4ms/step - loss: 4.3038 - RMSE: 1.1208 - val_loss: 4.2106 - val_RMSE: 1.1210\n",
            "Epoch 7/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 4.1211 - RMSE: 1.1201 - val_loss: 4.0335 - val_RMSE: 1.1203\n",
            "Epoch 8/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 3.9489 - RMSE: 1.1190 - val_loss: 3.8662 - val_RMSE: 1.1192\n",
            "Epoch 9/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 3.7864 - RMSE: 1.1176 - val_loss: 3.7085 - val_RMSE: 1.1183\n",
            "Epoch 10/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 3.6331 - RMSE: 1.1167 - val_loss: 3.5597 - val_RMSE: 1.1172\n",
            "Epoch 11/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 3.4884 - RMSE: 1.1155 - val_loss: 3.4193 - val_RMSE: 1.1162\n",
            "Epoch 12/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 3.3518 - RMSE: 1.1142 - val_loss: 3.2869 - val_RMSE: 1.1150\n",
            "Epoch 13/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 3.2229 - RMSE: 1.1130 - val_loss: 3.1616 - val_RMSE: 1.1136\n",
            "Epoch 14/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 3.1011 - RMSE: 1.1116 - val_loss: 3.0434 - val_RMSE: 1.1121\n",
            "Epoch 15/65\n",
            "147/147 [==============================] - 1s 7ms/step - loss: 2.9859 - RMSE: 1.1096 - val_loss: 2.9316 - val_RMSE: 1.1102\n",
            "Epoch 16/65\n",
            "147/147 [==============================] - 1s 7ms/step - loss: 2.8772 - RMSE: 1.1079 - val_loss: 2.8259 - val_RMSE: 1.1082\n",
            "Epoch 17/65\n",
            "147/147 [==============================] - 1s 7ms/step - loss: 2.7742 - RMSE: 1.1053 - val_loss: 2.7266 - val_RMSE: 1.1066\n",
            "Epoch 18/65\n",
            "147/147 [==============================] - 1s 7ms/step - loss: 2.6768 - RMSE: 1.1028 - val_loss: 2.6312 - val_RMSE: 1.1033\n",
            "Epoch 19/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.5844 - RMSE: 1.1001 - val_loss: 2.5415 - val_RMSE: 1.1003\n",
            "Epoch 20/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.4967 - RMSE: 1.0964 - val_loss: 2.4562 - val_RMSE: 1.0966\n",
            "Epoch 21/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.4135 - RMSE: 1.0925 - val_loss: 2.3759 - val_RMSE: 1.0933\n",
            "Epoch 22/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.3340 - RMSE: 1.0877 - val_loss: 2.2991 - val_RMSE: 1.0890\n",
            "Epoch 23/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.2585 - RMSE: 1.0825 - val_loss: 2.2248 - val_RMSE: 1.0829\n",
            "Epoch 24/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.1862 - RMSE: 1.0767 - val_loss: 2.1544 - val_RMSE: 1.0766\n",
            "Epoch 25/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.1173 - RMSE: 1.0697 - val_loss: 2.0876 - val_RMSE: 1.0702\n",
            "Epoch 26/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 2.0510 - RMSE: 1.0621 - val_loss: 2.0229 - val_RMSE: 1.0623\n",
            "Epoch 27/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.9874 - RMSE: 1.0535 - val_loss: 1.9615 - val_RMSE: 1.0544\n",
            "Epoch 28/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.9264 - RMSE: 1.0444 - val_loss: 1.9026 - val_RMSE: 1.0457\n",
            "Epoch 29/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.8681 - RMSE: 1.0348 - val_loss: 1.8467 - val_RMSE: 1.0371\n",
            "Epoch 30/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.8123 - RMSE: 1.0254 - val_loss: 1.7931 - val_RMSE: 1.0280\n",
            "Epoch 31/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.7591 - RMSE: 1.0149 - val_loss: 1.7427 - val_RMSE: 1.0196\n",
            "Epoch 32/65\n",
            "147/147 [==============================] - 1s 6ms/step - loss: 1.7090 - RMSE: 1.0057 - val_loss: 1.6949 - val_RMSE: 1.0113\n",
            "Epoch 33/65\n",
            "147/147 [==============================] - 1s 7ms/step - loss: 1.6616 - RMSE: 0.9968 - val_loss: 1.6503 - val_RMSE: 1.0040\n",
            "Epoch 34/65\n",
            "147/147 [==============================] - 1s 8ms/step - loss: 1.6171 - RMSE: 0.9880 - val_loss: 1.6085 - val_RMSE: 0.9974\n",
            "Epoch 35/65\n",
            "147/147 [==============================] - 1s 6ms/step - loss: 1.5752 - RMSE: 0.9807 - val_loss: 1.5693 - val_RMSE: 0.9914\n",
            "Epoch 36/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.5362 - RMSE: 0.9741 - val_loss: 1.5335 - val_RMSE: 0.9871\n",
            "Epoch 37/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.4996 - RMSE: 0.9680 - val_loss: 1.4991 - val_RMSE: 0.9824\n",
            "Epoch 38/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.4654 - RMSE: 0.9627 - val_loss: 1.4682 - val_RMSE: 0.9796\n",
            "Epoch 39/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.4335 - RMSE: 0.9583 - val_loss: 1.4361 - val_RMSE: 0.9740\n",
            "Epoch 40/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.4034 - RMSE: 0.9539 - val_loss: 1.4078 - val_RMSE: 0.9708\n",
            "Epoch 41/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.3753 - RMSE: 0.9502 - val_loss: 1.3816 - val_RMSE: 0.9683\n",
            "Epoch 42/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.3487 - RMSE: 0.9471 - val_loss: 1.3561 - val_RMSE: 0.9651\n",
            "Epoch 43/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.3240 - RMSE: 0.9438 - val_loss: 1.3334 - val_RMSE: 0.9636\n",
            "Epoch 44/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.3010 - RMSE: 0.9415 - val_loss: 1.3108 - val_RMSE: 0.9610\n",
            "Epoch 45/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.2790 - RMSE: 0.9386 - val_loss: 1.2903 - val_RMSE: 0.9594\n",
            "Epoch 46/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.2584 - RMSE: 0.9364 - val_loss: 1.2709 - val_RMSE: 0.9577\n",
            "Epoch 47/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.2393 - RMSE: 0.9345 - val_loss: 1.2527 - val_RMSE: 0.9563\n",
            "Epoch 48/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.2211 - RMSE: 0.9327 - val_loss: 1.2354 - val_RMSE: 0.9548\n",
            "Epoch 49/65\n",
            "147/147 [==============================] - 1s 7ms/step - loss: 1.2038 - RMSE: 0.9311 - val_loss: 1.2188 - val_RMSE: 0.9533\n",
            "Epoch 50/65\n",
            "147/147 [==============================] - 1s 7ms/step - loss: 1.1880 - RMSE: 0.9295 - val_loss: 1.2062 - val_RMSE: 0.9548\n",
            "Epoch 51/65\n",
            "147/147 [==============================] - 1s 8ms/step - loss: 1.1729 - RMSE: 0.9281 - val_loss: 1.1890 - val_RMSE: 0.9509\n",
            "Epoch 52/65\n",
            "147/147 [==============================] - 1s 6ms/step - loss: 1.1587 - RMSE: 0.9272 - val_loss: 1.1764 - val_RMSE: 0.9509\n",
            "Epoch 53/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.1456 - RMSE: 0.9259 - val_loss: 1.1630 - val_RMSE: 0.9494\n",
            "Epoch 54/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.1331 - RMSE: 0.9251 - val_loss: 1.1515 - val_RMSE: 0.9492\n",
            "Epoch 55/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.1214 - RMSE: 0.9242 - val_loss: 1.1405 - val_RMSE: 0.9488\n",
            "Epoch 56/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.1102 - RMSE: 0.9236 - val_loss: 1.1296 - val_RMSE: 0.9479\n",
            "Epoch 57/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0999 - RMSE: 0.9229 - val_loss: 1.1221 - val_RMSE: 0.9498\n",
            "Epoch 58/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0901 - RMSE: 0.9222 - val_loss: 1.1103 - val_RMSE: 0.9470\n",
            "Epoch 59/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0809 - RMSE: 0.9218 - val_loss: 1.1020 - val_RMSE: 0.9471\n",
            "Epoch 60/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0721 - RMSE: 0.9214 - val_loss: 1.0926 - val_RMSE: 0.9457\n",
            "Epoch 61/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0641 - RMSE: 0.9209 - val_loss: 1.0855 - val_RMSE: 0.9461\n",
            "Epoch 62/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0564 - RMSE: 0.9207 - val_loss: 1.0773 - val_RMSE: 0.9450\n",
            "Epoch 63/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0491 - RMSE: 0.9203 - val_loss: 1.0708 - val_RMSE: 0.9452\n",
            "Epoch 64/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0423 - RMSE: 0.9198 - val_loss: 1.0668 - val_RMSE: 0.9476\n",
            "Epoch 65/65\n",
            "147/147 [==============================] - 1s 5ms/step - loss: 1.0359 - RMSE: 0.9199 - val_loss: 1.0579 - val_RMSE: 0.9447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습과정에서 측정지표의 변화\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['RMSE'], label=\"Train RMSE\")\n",
        "plt.plot(result.history['val_RMSE'], label=\"Test RMSE\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('RMSE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lJ9THnS0N9nI",
        "outputId": "eafb8788-74f1-492b-c1f8-a40f04cce6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망에서 예측한 결과의 실제 RMSE 계산\n",
        "def RMSE2(y_true, y_pred):\n",
        "    return np.sqrt( np.mean( ( np.array(y_true) - np.array(y_pred) )**2 ) )\n",
        "\n",
        "user_ids = ratings_test.user_id.values\n",
        "movie_ids = ratings_test.movie_id.values\n",
        "\n",
        "y_pred = model.predict([user_ids, movie_ids]) + mu\n",
        "# Keras의 Model 클래스에서 제공하는 predict() 메소드는 신경망에 입력을 넣어주면 해당 신경망을 적용한 예측값을 계산해준다.\n",
        "y_pred = np.ravel(y_pred, order = 'C')\n",
        "# predict()로 얻은 예측값은 2차원(N X 1)의 array로 되어있으므로 np.ravel을 사용, 1차원 array로 바꿔준다.\n",
        "y_true = np.array(ratings_test.rating)\n",
        "# 실제 평점값을 가져온다.\n",
        "RMSE2(y_true, y_pred)"
      ],
      "metadata": {
        "id": "hINzk-3COKxt",
        "outputId": "d45bd183-8108-4946-c1b1-c1dd37a272ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9450759256957006"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 하이브리드 모델"
      ],
      "metadata": {
        "id": "9jlnvJkpORe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Hybrid 추천 알고리즘\n",
        "\n",
        "def recommender0(recomm_list, mf):              # MF 알고리즘의 예측값을 받아오는 함수이다. \n",
        "    recommendations = np.array([mf.get_one_prediction(user, movie) for (user, movie) in recomm_list])\n",
        "    # 추천대상 리스트(recomm_list)의 항목 각각에 대해서 MF클래스의 get_one_prediction() 함수를 불러서 예측값을 받아온 후에 np.array로 변환한다.\n",
        "    return recommendations\n",
        "\n",
        "def recommender1(recomm_list, model):           # DL 알고리즘의 예측값을 받아오는 함수이다.\n",
        "    for (user, movie) in recomm_list:\n",
        "      recommendations = model.predict([user, movie]) + mu\n",
        "      # 추천대상 리스트(recomm_list)의 항목 각각에 대해서 Keras의 Model 클래스에서 제공하는 predict() 메소드는 신경망에 입력을 넣어주면 \n",
        "      # 해당 신경망을 적용한 예측값을 계산해준다. \n",
        "      recommendations = np.ravel(recommendations, order = 'C')\n",
        "      # predict()로 얻은 예측값은 2차원(N X 1)의 array로 되어있으므로 np.ravel을 사용, 1차원 array로 바꿔준다.\n",
        "      # 예측값을 받아온 후에 np.array로 변환한다.\n",
        "    return recommendations\n",
        "\n",
        "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])      # test set을 np.array형식의 추천 대상 리스트로 만든다.\n",
        "predictions0 = recommender0(recomm_list, mf)              # MF기반 알고리즘의 예측값을 받아온다.\n",
        "RMSE(ratings_test.iloc[:, 2], predictions0)               # MF기반 알고리즘의 RMSE를 계산한다.\n",
        "predictions1 = recommender1(recomm_list, model)           # DL기반 알고리즘의 예측값을 받아온다.\n",
        "RMSE(ratings_test.iloc[:, 2], predictions1)               # DL기반 알고리즘의 RMSE를 계산한다.\n",
        "\n",
        "weight = [0.8, 0.2]                                                 # 두 알고리즘의 결합 가중치를 지정한다.\n",
        "predictions = predictions0 * weight[0] + predictions1 * weight[1]   # 가중치에 따라 두 추천 알고리즘에서 가져온 예측값을 가중평균한다.\n",
        "RMSE(ratings_test.iloc[:, 2], predictions)                          # 하이브리드 모델의 RMSE를 계산한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "DxWG_gO3HJtP",
        "outputId": "d5713827-e8e9-4242-8fe2-bd86e6152aa5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-19f489ac442e>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mpredictions0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# MF기반 알고리즘의 예측값을 받아온다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions0\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# MF기반 알고리즘의 RMSE를 계산한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpredictions1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# DL기반 알고리즘의 예측값을 받아온다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions1\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# DL기반 알고리즘의 RMSE를 계산한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-19f489ac442e>\u001b[0m in \u001b[0;36mrecommender1\u001b[0;34m(recomm_list, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecommender1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0;31m# DL 알고리즘의 예측값을 받아오는 함수이다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecomm_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;31m# 추천대상 리스트(recomm_list)의 항목 각각에 대해서 Keras의 Model 클래스에서 제공하는 predict() 메소드는 신경망에 입력을 넣어주면\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;31m# 해당 신경망을 적용한 예측값을 계산해준다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1083\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1084\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.int64'>\"}), <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치를 0~1까지 0.01 간격으로 바꿔가면서 RMSE 계산\n",
        "for i in np.arange(0, 1, 0.01):\n",
        "    weight = [i, 1.0 - i]\n",
        "    predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
        "    print(\"Weights - %.2f : %.2f ; RMSE = %.7f\" % (weight[0], \n",
        "           weight[1], RMSE(ratings_test.iloc[:, 2], predictions)))"
      ],
      "metadata": {
        "id": "9E1mKDWsRGRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 베스트 : Weights - 0.91 : 0.09 ; RMSE = 0.9069064\n",
        "\n",
        "\n",
        "                    (MF-SGD 91%, DL   %)"
      ],
      "metadata": {
        "id": "PYuPRVdHSAhF"
      }
    }
  ]
}