{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CP2J/cp2j/blob/ACJ-9-MF-SGD-/Recsys_MF_SGD(normal%20init).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BJGCsWgzp_Z4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "rating = pd.read_csv('/content/drive/MyDrive/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUBUOdF6VWbV",
        "outputId": "7761bc07-84c8-43cb-ba46-c59df889f4b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # MF-SGD (Matrix Factorization - Stochastic Gradient Descent)\n",
        "\n",
        " SVD에서 쓰인 행렬분해를 이용, 확률적 경사하강 기법으로 오차를 줄이는 방향으로 학습한다.  \n",
        "SVD의 행렬분해에서는 null값이 존재하면 안되기에 평균값, 최빈값 등을 사용했으나 여기서는 랜덤값 지정 후 오차를 줄이는 방향으로 학습.  \n",
        "결국 데이터가 sparse 할 수록 임의값에 의존하던 이전 모델들에 비해 성능이 더 잘 나오게 된다."
      ],
      "metadata": {
        "id": "tRma3N1V3c9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# files.upload();\n",
        "# rating = pd.read_csv('ratings.csv')"
      ],
      "metadata": {
        "id": "-z4IzJK8qNb_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qsDiruJpwl1Q",
        "outputId": "ed36e70e-6690-4664-fa63-7964bd45e6c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_id  item_id  rating  timestamp\n",
              "0          196      242       3  881250949\n",
              "1          186      302       3  891717742\n",
              "2           22      377       1  878887116\n",
              "3          244       51       2  880606923\n",
              "4          166      346       1  886397596\n",
              "...        ...      ...     ...        ...\n",
              "99995      880      476       3  880175444\n",
              "99996      716      204       5  879795543\n",
              "99997      276     1090       1  874795795\n",
              "99998       13      225       2  882399156\n",
              "99999       12      203       3  879959583\n",
              "\n",
              "[100000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95c51a2b-f925-4af4-adbd-4ddba8f7e6b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>880</td>\n",
              "      <td>476</td>\n",
              "      <td>3</td>\n",
              "      <td>880175444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>716</td>\n",
              "      <td>204</td>\n",
              "      <td>5</td>\n",
              "      <td>879795543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>276</td>\n",
              "      <td>1090</td>\n",
              "      <td>1</td>\n",
              "      <td>874795795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>13</td>\n",
              "      <td>225</td>\n",
              "      <td>2</td>\n",
              "      <td>882399156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>12</td>\n",
              "      <td>203</td>\n",
              "      <td>3</td>\n",
              "      <td>879959583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95c51a2b-f925-4af4-adbd-4ddba8f7e6b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95c51a2b-f925-4af4-adbd-4ddba8f7e6b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95c51a2b-f925-4af4-adbd-4ddba8f7e6b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train시 embedding layer 필요, df.pivot으로 해결되는지 추후 실험 필요\n"
      ],
      "metadata": {
        "id": "OMr2AyURJHId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split 수행\n",
        "\n",
        "train data를 연속적 값으로 변환하는 목적(빠진 값이 있을 것, svd 함수 내 설명 참고)\n"
      ],
      "metadata": {
        "id": "8COLGEjxMV3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating = rating.drop(columns = ['timestamp'])"
      ],
      "metadata": {
        "id": "odldDxttNhUf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "rating_train, rating_test = train_test_split(rating, test_size = 0.2)\n",
        "\n",
        "rating_train = rating_train.reset_index()[['user_id', 'item_id', 'rating']]\n",
        "rating_test = rating_test.reset_index()[['user_id', 'item_id', 'rating']]"
      ],
      "metadata": {
        "id": "n6g5pUXALpbX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_column(column):\n",
        "  # 컬럼 을 연속 id로 인코딩\n",
        "  # 열 내 고유값 키\n",
        "  keys = column.unique()\n",
        "  #enumerate = 리스트 내 넘버와 값\n",
        "  key_to_id = {key:idx for idx, key in enumerate(keys)}\n",
        "  return key_to_id, np.array([key_to_id[x] for x in column]), len(keys)"
      ],
      "metadata": {
        "id": "-c9fHRri4whW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_df(rating):\n",
        "  #rating 데이터를 연속적인 user와 item id 로 재 배열\n",
        "  #encode_column의 결과 값으로 들어온 df의 열 데이터를 바꿔서 반환\n",
        "  item_ids, rating['item_id'], num_item = encode_column(rating['item_id'])\n",
        "  user_ids, rating['user_id'], num_user = encode_column(rating['user_id'])\n",
        "  return rating, num_user, num_item, user_ids, item_ids"
      ],
      "metadata": {
        "id": "qjaD5Wd3KAPd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df, num_user, num_item, user_ids, item_ids = encode_df(rating_train)\n",
        "print(\"Number of Users : \", num_user)\n",
        "print(\"Number of Items : \", num_item)\n",
        "rating_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fd2YfuT6MUVc",
        "outputId": "88b24033-2216-436b-a31d-1f6de9a7306b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Users :  943\n",
            "Number of Items :  1647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rating\n",
              "0        0        0       4\n",
              "1        1        1       5\n",
              "2        2        2       4\n",
              "3        3        3       5\n",
              "4        4        4       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68098701-f245-4fad-b241-1547f51bf707\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68098701-f245-4fad-b241-1547f51bf707')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68098701-f245-4fad-b241-1547f51bf707 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68098701-f245-4fad-b241-1547f51bf707');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User and Item embeddings"
      ],
      "metadata": {
        "id": "Y27qSRMtO1z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings(n, K):\n",
        "  # 랜덤한 값의 넘파이 행력 생성 함수 (n, K)\n",
        "  # n = 아이템/유저의 수\n",
        "  # K = embedding 안의 고유값 개수\n",
        "  return 5* np.random.random((n, K)) / K"
      ],
      "metadata": {
        "id": "ms_PxhJUOy03"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sparse_matrix(df, rows, columns, column_name = 'rating'):\n",
        "  # scipy를 이용해 Sparse utility matrix 생성 함수\n",
        "  return sparse.csc_matrix((df[column_name].values, (df['user_id'].values, df['item_id'].values)),shape = (rows, columns))"
      ],
      "metadata": {
        "id": "pBGpW6JUNbEb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df, num_user, num_item, user_ids, item_ids = encode_df(rating_train)\n",
        "Y = create_sparse_matrix(rating_df, num_user, num_item)"
      ],
      "metadata": {
        "id": "BljydfEvQFrQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcA8M2GeQWsz",
        "outputId": "c4c8642d-2dde-4c07-ccb4-546905b9ffb7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[4, 0, 3, ..., 0, 0, 0],\n",
              "        [0, 5, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 4, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측값 함수"
      ],
      "metadata": {
        "id": "Xtsx2CdlTB4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(df, emb_user, emb_item):\n",
        "  # 행렬곱(U * V^T) 없이 예측값을 돌려주는 함수\n",
        "  # embedding 끼리의 같은 위치에 있는 값들의 곱(elementwise multiplication)의 합으로 u_i* v_j의 합을 구함\n",
        "  # 이걸로 U * V^T를 위한 행렬 생성이 필요없게 된다\n",
        "  df['prediction'] = np.sum(np.multiply(emb_item[df['item_id']], emb_user[df['user_id']]), axis = 1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "rT8eRRWIQdLK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "비용함수"
      ],
      "metadata": {
        "id": "NvN1CkWLTOzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZdbmxYW8Tqie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lmbda = 0.0002"
      ],
      "metadata": {
        "id": "QD4bkUr_V_hf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(df, emb_user, emb_item) :\n",
        "  Y = create_sparse_matrix(df, emb_user.shape[0], emb_item.shape[0])\n",
        "  predicted = create_sparse_matrix(predict(df, emb_user, emb_item), emb_user.shape[0], emb_item.shape[0], 'prediction')\n",
        "  return np.sqrt(np.sum((Y-predicted).power(2))/df.shape[0])"
      ],
      "metadata": {
        "id": "zsoPPhIlTJM-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent(경사하강)"
      ],
      "metadata": {
        "id": "XjNi4SV6WFeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient(df, emb_user, emb_item):\n",
        "  # embedding에 적용할 경사 설정\n",
        "  Y = create_sparse_matrix(df, emb_user.shape[0], emb_item.shape[0])\n",
        "  predicted = create_sparse_matrix(predict(df, emb_user, emb_item), emb_user.shape[0], emb_item.shape[0], 'prediction')\n",
        "  delta = (Y-predicted)\n",
        "  grad_user = (-2/df.shape[0])*(delta*emb_item) + 2*lmbda*emb_user\n",
        "  grad_item = (-2/df.shape[0])*(delta.T*emb_user) + 2*lmbda*emb_item\n",
        "  return grad_user, grad_item"
      ],
      "metadata": {
        "id": "-fo3KxTzVvAU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(df, emb_user, emb_item, iterations = 2000, learning_rate=0.01, df_val = None):\n",
        "  Y = create_sparse_matrix(df, emb_user.shape[0], emb_item.shape[0])\n",
        "  beta = 0.9\n",
        "  grad_user, grad_item = gradient(df, emb_user, emb_item)\n",
        "  v_user = grad_user\n",
        "  v_item = grad_item\n",
        "  for i in range(iterations):\n",
        "    grad_user, grad_item = gradient(df, emb_user, emb_item)\n",
        "    v_user = beta*v_user + (1-beta)*grad_user\n",
        "    v_item = beta*v_item + (1-beta)*grad_item\n",
        "    emb_user = emb_user - learning_rate*v_user\n",
        "    emb_item = emb_item - learning_rate*v_item\n",
        "    if (i+1) % 50 == 0:\n",
        "      print('\\niteration', i+1, \":\")\n",
        "      print(\"train rmse : \", cost(df, emb_user, emb_item))\n",
        "      if df_val is not None:\n",
        "        print('validation rmse : ', cost(df_val, emb_user, emb_item))\n",
        "  return emb_user, emb_item"
      ],
      "metadata": {
        "id": "89-uolYPq0JO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_user = create_embeddings(num_user, 3)\n",
        "emb_item = create_embeddings(num_item, 3)\n",
        "emb_user, emb_item = gradient_descent(rating_df, emb_user, emb_item, iterations = 3000, learning_rate = 0.02)#, df_val = rating_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG6rqkRqu8JY",
        "outputId": "a9de81b5-289f-4929-f08f-fa7e88f75618"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "iteration 50 :\n",
            "train rmse :  2.0981336457531103\n",
            "\n",
            "iteration 100 :\n",
            "train rmse :  2.0819945861241322\n",
            "\n",
            "iteration 150 :\n",
            "train rmse :  2.066065042043993\n",
            "\n",
            "iteration 200 :\n",
            "train rmse :  2.0503448910399444\n",
            "\n",
            "iteration 250 :\n",
            "train rmse :  2.034833927804751\n",
            "\n",
            "iteration 300 :\n",
            "train rmse :  2.019531890331309\n",
            "\n",
            "iteration 350 :\n",
            "train rmse :  2.0044384549967913\n",
            "\n",
            "iteration 400 :\n",
            "train rmse :  1.989553232149667\n",
            "\n",
            "iteration 450 :\n",
            "train rmse :  1.9748757623332982\n",
            "\n",
            "iteration 500 :\n",
            "train rmse :  1.9604055131168487\n",
            "\n",
            "iteration 550 :\n",
            "train rmse :  1.946141876503615\n",
            "\n",
            "iteration 600 :\n",
            "train rmse :  1.93208416688717\n",
            "\n",
            "iteration 650 :\n",
            "train rmse :  1.9182316195259226\n",
            "\n",
            "iteration 700 :\n",
            "train rmse :  1.9045833895069666\n",
            "\n",
            "iteration 750 :\n",
            "train rmse :  1.8911385511703602\n",
            "\n",
            "iteration 800 :\n",
            "train rmse :  1.877896097965259\n",
            "\n",
            "iteration 850 :\n",
            "train rmse :  1.8648549427096763\n",
            "\n",
            "iteration 900 :\n",
            "train rmse :  1.852013918225997\n",
            "\n",
            "iteration 950 :\n",
            "train rmse :  1.839371778324801\n",
            "\n",
            "iteration 1000 :\n",
            "train rmse :  1.8269271991100025\n",
            "\n",
            "iteration 1050 :\n",
            "train rmse :  1.8146787805788378\n",
            "\n",
            "iteration 1100 :\n",
            "train rmse :  1.8026250484907878\n",
            "\n",
            "iteration 1150 :\n",
            "train rmse :  1.790764456480141\n",
            "\n",
            "iteration 1200 :\n",
            "train rmse :  1.7790953883875733\n",
            "\n",
            "iteration 1250 :\n",
            "train rmse :  1.7676161607868246\n",
            "\n",
            "iteration 1300 :\n",
            "train rmse :  1.756325025683322\n",
            "\n",
            "iteration 1350 :\n",
            "train rmse :  1.7452201733623962\n",
            "\n",
            "iteration 1400 :\n",
            "train rmse :  1.7342997353655851\n",
            "\n",
            "iteration 1450 :\n",
            "train rmse :  1.723561787574392\n",
            "\n",
            "iteration 1500 :\n",
            "train rmse :  1.7130043533817803\n",
            "\n",
            "iteration 1550 :\n",
            "train rmse :  1.702625406932617\n",
            "\n",
            "iteration 1600 :\n",
            "train rmse :  1.6924228764152425\n",
            "\n",
            "iteration 1650 :\n",
            "train rmse :  1.6823946473873113\n",
            "\n",
            "iteration 1700 :\n",
            "train rmse :  1.6725385661200405\n",
            "\n",
            "iteration 1750 :\n",
            "train rmse :  1.662852442945995\n",
            "\n",
            "iteration 1800 :\n",
            "train rmse :  1.6533340555965303\n",
            "\n",
            "iteration 1850 :\n",
            "train rmse :  1.6439811525160204\n",
            "\n",
            "iteration 1900 :\n",
            "train rmse :  1.634791456140963\n",
            "\n",
            "iteration 1950 :\n",
            "train rmse :  1.6257626661330513\n",
            "\n",
            "iteration 2000 :\n",
            "train rmse :  1.616892462556245\n",
            "\n",
            "iteration 2050 :\n",
            "train rmse :  1.6081785089888194\n",
            "\n",
            "iteration 2100 :\n",
            "train rmse :  1.599618455562289\n",
            "\n",
            "iteration 2150 :\n",
            "train rmse :  1.5912099419199845\n",
            "\n",
            "iteration 2200 :\n",
            "train rmse :  1.582950600088938\n",
            "\n",
            "iteration 2250 :\n",
            "train rmse :  1.5748380572595415\n",
            "\n",
            "iteration 2300 :\n",
            "train rmse :  1.566869938468258\n",
            "\n",
            "iteration 2350 :\n",
            "train rmse :  1.5590438691794093\n",
            "\n",
            "iteration 2400 :\n",
            "train rmse :  1.551357477762799\n",
            "\n",
            "iteration 2450 :\n",
            "train rmse :  1.543808397864606\n",
            "\n",
            "iteration 2500 :\n",
            "train rmse :  1.5363942706696303\n",
            "\n",
            "iteration 2550 :\n",
            "train rmse :  1.5291127470535821\n",
            "\n",
            "iteration 2600 :\n",
            "train rmse :  1.5219614896246607\n",
            "\n",
            "iteration 2650 :\n",
            "train rmse :  1.5149381746542074\n",
            "\n",
            "iteration 2700 :\n",
            "train rmse :  1.5080404938966916\n",
            "\n",
            "iteration 2750 :\n",
            "train rmse :  1.5012661562997343\n",
            "\n",
            "iteration 2800 :\n",
            "train rmse :  1.494612889605291\n",
            "\n",
            "iteration 2850 :\n",
            "train rmse :  1.488078441843472\n",
            "\n",
            "iteration 2900 :\n",
            "train rmse :  1.4816605827208182\n",
            "\n",
            "iteration 2950 :\n",
            "train rmse :  1.4753571049051428\n",
            "\n",
            "iteration 3000 :\n",
            "train rmse :  1.4691658252093198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_new_data(val_df, user_ids, item_ids):\n",
        "  val_df_chosen = val_df['item_id'].isin(item_ids.keys())&val_df['user_id'].isin(user_ids.keys())\n",
        "  val_df = val_df[val_df_chosen]\n",
        "  val_df['user_id'] = np.array([user_ids[x] for x in val_df['user_id']])\n",
        "  val_df['item_id'] = np.array([item_ids[x] for x in val_df['item_id']])\n",
        "  return val_df"
      ],
      "metadata": {
        "id": "0OS_oXTPxMfd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('before encoding :', rating_test.shape)\n",
        "rating_test = encode_new_data(rating_test, user_ids, item_ids)\n",
        "print('after encoding :', rating_test.shape)"
      ],
      "metadata": {
        "id": "JxzT9h3rzj4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d183e70-485b-4ccc-df0e-3ccbbb43d5e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before encoding : (20000, 3)\n",
            "after encoding : (19952, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9d15276c8cb0>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_df['user_id'] = np.array([user_ids[x] for x in val_df['user_id']])\n",
            "<ipython-input-20-9d15276c8cb0>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_df['item_id'] = np.array([item_ids[x] for x in val_df['item_id']])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_rmse = cost(rating_df, emb_user, emb_item)\n",
        "val_rmse = cost(rating_test, emb_user, emb_item)\n",
        "print(train_rmse, val_rmse)"
      ],
      "metadata": {
        "id": "9MlJHHQh1xVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90dcfe3b-1ca6-4cf0-d47a-322deffe1724"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4691658252093198 1.8008156198021856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-091853279785>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['prediction'] = np.sum(np.multiply(emb_item[df['item_id']], emb_user[df['user_id']]), axis = 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vt6pGrzc2Lnv",
        "outputId": "e8359648-9ecb-47f5-ff83-032e163e713d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_id  item_id  rating  prediction\n",
              "0          407        1       4    1.502822\n",
              "1          280      288       5    2.815957\n",
              "2          707       93       5    2.077619\n",
              "3          218      265       3    2.906563\n",
              "4          939      476       5    3.008769\n",
              "...        ...      ...     ...         ...\n",
              "19995       72      866       4    3.404354\n",
              "19996      303      568       4    3.092393\n",
              "19997       92       38       3    4.252924\n",
              "19998      393      627       4    2.651378\n",
              "19999      864       28       5    2.975939\n",
              "\n",
              "[19952 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6c00d42-aebc-4f68-9bdb-0f80426a4708\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>407</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1.502822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>280</td>\n",
              "      <td>288</td>\n",
              "      <td>5</td>\n",
              "      <td>2.815957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>707</td>\n",
              "      <td>93</td>\n",
              "      <td>5</td>\n",
              "      <td>2.077619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>218</td>\n",
              "      <td>265</td>\n",
              "      <td>3</td>\n",
              "      <td>2.906563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>939</td>\n",
              "      <td>476</td>\n",
              "      <td>5</td>\n",
              "      <td>3.008769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>72</td>\n",
              "      <td>866</td>\n",
              "      <td>4</td>\n",
              "      <td>3.404354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>303</td>\n",
              "      <td>568</td>\n",
              "      <td>4</td>\n",
              "      <td>3.092393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>92</td>\n",
              "      <td>38</td>\n",
              "      <td>3</td>\n",
              "      <td>4.252924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>393</td>\n",
              "      <td>627</td>\n",
              "      <td>4</td>\n",
              "      <td>2.651378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>864</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>2.975939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19952 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6c00d42-aebc-4f68-9bdb-0f80426a4708')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6c00d42-aebc-4f68-9bdb-0f80426a4708 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6c00d42-aebc-4f68-9bdb-0f80426a4708');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_user = create_embeddings(num_user, 3)\n",
        "emb_item = create_embeddings(num_item, 3)\n",
        "emb_user, emb_item = gradient_descent(rating_df, emb_user, emb_item, iterations = 5000, learning_rate = 0.2, df_val = rating_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVkL1-1R2Z0f",
        "outputId": "3577e26e-8da6-4034-ad99-bad9b129842f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "iteration 50 :\n",
            "train rmse :  1.9579469675651966\n",
            "validation rmse :  2.0256940675786863\n",
            "\n",
            "iteration 100 :\n",
            "train rmse :  1.8184862079060893\n",
            "validation rmse :  1.9525507590943154\n",
            "\n",
            "iteration 150 :\n",
            "train rmse :  1.6998226915487011\n",
            "validation rmse :  1.8893283039017243\n",
            "\n",
            "iteration 200 :\n",
            "train rmse :  1.6002310875164185\n",
            "validation rmse :  1.8352171648641116\n",
            "\n",
            "iteration 250 :\n",
            "train rmse :  1.517389797844767\n",
            "validation rmse :  1.789140515872427\n",
            "\n",
            "iteration 300 :\n",
            "train rmse :  1.4487499438368199\n",
            "validation rmse :  1.7499423285666882\n",
            "\n",
            "iteration 350 :\n",
            "train rmse :  1.391843989982188\n",
            "validation rmse :  1.716519238092268\n",
            "\n",
            "iteration 400 :\n",
            "train rmse :  1.3444740917276758\n",
            "validation rmse :  1.687891829937443\n",
            "\n",
            "iteration 450 :\n",
            "train rmse :  1.304788034766048\n",
            "validation rmse :  1.6632294927169482\n",
            "\n",
            "iteration 500 :\n",
            "train rmse :  1.2712793489918865\n",
            "validation rmse :  1.6418471088832929\n",
            "\n",
            "iteration 550 :\n",
            "train rmse :  1.2427483573623495\n",
            "validation rmse :  1.623188253494727\n",
            "\n",
            "iteration 600 :\n",
            "train rmse :  1.2182498799748065\n",
            "validation rmse :  1.6068041755172764\n",
            "\n",
            "iteration 650 :\n",
            "train rmse :  1.1970417955175139\n",
            "validation rmse :  1.5923334156662918\n",
            "\n",
            "iteration 700 :\n",
            "train rmse :  1.1785405556095259\n",
            "validation rmse :  1.5794840866977953\n",
            "\n",
            "iteration 750 :\n",
            "train rmse :  1.1622851782323573\n",
            "validation rmse :  1.568019313760473\n",
            "\n",
            "iteration 800 :\n",
            "train rmse :  1.1479091307739564\n",
            "validation rmse :  1.5577456315413838\n",
            "\n",
            "iteration 850 :\n",
            "train rmse :  1.1351187791306225\n",
            "validation rmse :  1.5485038851077255\n",
            "\n",
            "iteration 900 :\n",
            "train rmse :  1.1236770039692867\n",
            "validation rmse :  1.5401621467076339\n",
            "\n",
            "iteration 950 :\n",
            "train rmse :  1.1133907665057041\n",
            "validation rmse :  1.5326102131738712\n",
            "\n",
            "iteration 1000 :\n",
            "train rmse :  1.1041016504661807\n",
            "validation rmse :  1.5257553257991325\n",
            "\n",
            "iteration 1050 :\n",
            "train rmse :  1.0956786347274077\n",
            "validation rmse :  1.5195188299679063\n",
            "\n",
            "iteration 1100 :\n",
            "train rmse :  1.08801253776726\n",
            "validation rmse :  1.513833556108067\n",
            "\n",
            "iteration 1150 :\n",
            "train rmse :  1.081011718969853\n",
            "validation rmse :  1.5086417549888114\n",
            "\n",
            "iteration 1200 :\n",
            "train rmse :  1.0745987294782782\n",
            "validation rmse :  1.5038934603039391\n",
            "\n",
            "iteration 1250 :\n",
            "train rmse :  1.068707684658639\n",
            "validation rmse :  1.499545181930383\n",
            "\n",
            "iteration 1300 :\n",
            "train rmse :  1.063282188442055\n",
            "validation rmse :  1.495558856301908\n",
            "\n",
            "iteration 1350 :\n",
            "train rmse :  1.0582736824869297\n",
            "validation rmse :  1.4919009977338282\n",
            "\n",
            "iteration 1400 :\n",
            "train rmse :  1.053640124486719\n",
            "validation rmse :  1.4885420076620535\n",
            "\n",
            "iteration 1450 :\n",
            "train rmse :  1.0493449231348315\n",
            "validation rmse :  1.4854556086821156\n",
            "\n",
            "iteration 1500 :\n",
            "train rmse :  1.045356074483993\n",
            "validation rmse :  1.482618377793562\n",
            "\n",
            "iteration 1550 :\n",
            "train rmse :  1.0416454573107352\n",
            "validation rmse :  1.4800093589727328\n",
            "\n",
            "iteration 1600 :\n",
            "train rmse :  1.0381882547742907\n",
            "validation rmse :  1.477609739560572\n",
            "\n",
            "iteration 1650 :\n",
            "train rmse :  1.034962476979323\n",
            "validation rmse :  1.475402578295682\n",
            "\n",
            "iteration 1700 :\n",
            "train rmse :  1.0319485646206583\n",
            "validation rmse :  1.473372575395629\n",
            "\n",
            "iteration 1750 :\n",
            "train rmse :  1.0291290581486032\n",
            "validation rmse :  1.4715058770778966\n",
            "\n",
            "iteration 1800 :\n",
            "train rmse :  1.0264883201710004\n",
            "validation rmse :  1.4697899084556056\n",
            "\n",
            "iteration 1850 :\n",
            "train rmse :  1.0240123013431977\n",
            "validation rmse :  1.4682132299471868\n",
            "\n",
            "iteration 1900 :\n",
            "train rmse :  1.0216883419681715\n",
            "validation rmse :  1.4667654132828347\n",
            "\n",
            "iteration 1950 :\n",
            "train rmse :  1.0195050030694994\n",
            "validation rmse :  1.465436933933694\n",
            "\n",
            "iteration 2000 :\n",
            "train rmse :  1.0174519219099032\n",
            "validation rmse :  1.4642190773778347\n",
            "\n",
            "iteration 2050 :\n",
            "train rmse :  1.01551968788324\n",
            "validation rmse :  1.463103857084824\n",
            "\n",
            "iteration 2100 :\n",
            "train rmse :  1.0136997354655077\n",
            "validation rmse :  1.4620839424745495\n",
            "\n",
            "iteration 2150 :\n",
            "train rmse :  1.0119842515142952\n",
            "validation rmse :  1.4611525954063387\n",
            "\n",
            "iteration 2200 :\n",
            "train rmse :  1.010366094689693\n",
            "validation rmse :  1.4603036139968641\n",
            "\n",
            "iteration 2250 :\n",
            "train rmse :  1.0088387251586832\n",
            "validation rmse :  1.4595312827621159\n",
            "\n",
            "iteration 2300 :\n",
            "train rmse :  1.0073961430593794\n",
            "validation rmse :  1.4588303282391368\n",
            "\n",
            "iteration 2350 :\n",
            "train rmse :  1.0060328344566594\n",
            "validation rmse :  1.4581958793746927\n",
            "\n",
            "iteration 2400 :\n",
            "train rmse :  1.0047437237287176\n",
            "validation rmse :  1.457623432076278\n",
            "\n",
            "iteration 2450 :\n",
            "train rmse :  1.0035241314943577\n",
            "validation rmse :  1.4571088174104119\n",
            "\n",
            "iteration 2500 :\n",
            "train rmse :  1.0023697373308333\n",
            "validation rmse :  1.456648173007585\n",
            "\n",
            "iteration 2550 :\n",
            "train rmse :  1.001276546647576\n",
            "validation rmse :  1.4562379172953572\n",
            "\n",
            "iteration 2600 :\n",
            "train rmse :  1.000240861176915\n",
            "validation rmse :  1.4558747262331928\n",
            "\n",
            "iteration 2650 :\n",
            "train rmse :  0.9992592526225355\n",
            "validation rmse :  1.45555551226651\n",
            "\n",
            "iteration 2700 :\n",
            "train rmse :  0.9983285390729439\n",
            "validation rmse :  1.4552774052545139\n",
            "\n",
            "iteration 2750 :\n",
            "train rmse :  0.9974457638429524\n",
            "validation rmse :  1.4550377351578996\n",
            "\n",
            "iteration 2800 :\n",
            "train rmse :  0.9966081764530889\n",
            "validation rmse :  1.454834016299365\n",
            "\n",
            "iteration 2850 :\n",
            "train rmse :  0.9958132154964191\n",
            "validation rmse :  1.454663933032861\n",
            "\n",
            "iteration 2900 :\n",
            "train rmse :  0.9950584931757902\n",
            "validation rmse :  1.4545253266772362\n",
            "\n",
            "iteration 2950 :\n",
            "train rmse :  0.9943417813229904\n",
            "validation rmse :  1.4544161835869576\n",
            "\n",
            "iteration 3000 :\n",
            "train rmse :  0.9936609987356075\n",
            "validation rmse :  1.4543346242472859\n",
            "\n",
            "iteration 3050 :\n",
            "train rmse :  0.9930141996881364\n",
            "validation rmse :  1.4542788932940574\n",
            "\n",
            "iteration 3100 :\n",
            "train rmse :  0.9923995634916944\n",
            "validation rmse :  1.4542473503693198\n",
            "\n",
            "iteration 3150 :\n",
            "train rmse :  0.9918153849920374\n",
            "validation rmse :  1.4542384617337794\n",
            "\n",
            "iteration 3200 :\n",
            "train rmse :  0.9912600659087798\n",
            "validation rmse :  1.4542507925654855\n",
            "\n",
            "iteration 3250 :\n",
            "train rmse :  0.9907321069301731\n",
            "validation rmse :  1.4542829998816427\n",
            "\n",
            "iteration 3300 :\n",
            "train rmse :  0.9902301004877025\n",
            "validation rmse :  1.4543338260269851\n",
            "\n",
            "iteration 3350 :\n",
            "train rmse :  0.9897527241434079\n",
            "validation rmse :  1.454402092677938\n",
            "\n",
            "iteration 3400 :\n",
            "train rmse :  0.9892987345303416\n",
            "validation rmse :  1.4544866953168978\n",
            "\n",
            "iteration 3450 :\n",
            "train rmse :  0.9888669617931634\n",
            "validation rmse :  1.4545865981355042\n",
            "\n",
            "iteration 3500 :\n",
            "train rmse :  0.9884563044816207\n",
            "validation rmse :  1.4547008293297932\n",
            "\n",
            "iteration 3550 :\n",
            "train rmse :  0.9880657248547281\n",
            "validation rmse :  1.4548284767537083\n",
            "\n",
            "iteration 3600 :\n",
            "train rmse :  0.9876942445579003\n",
            "validation rmse :  1.4549686839006448\n",
            "\n",
            "iteration 3650 :\n",
            "train rmse :  0.9873409406392226\n",
            "validation rmse :  1.4551206461855435\n",
            "\n",
            "iteration 3700 :\n",
            "train rmse :  0.9870049418745009\n",
            "validation rmse :  1.455283607502625\n",
            "\n",
            "iteration 3750 :\n",
            "train rmse :  0.9866854253738068\n",
            "validation rmse :  1.4554568570361233\n",
            "\n",
            "iteration 3800 :\n",
            "train rmse :  0.9863816134449499\n",
            "validation rmse :  1.4556397263034508\n",
            "\n",
            "iteration 3850 :\n",
            "train rmse :  0.9860927706917286\n",
            "validation rmse :  1.4558315864120646\n",
            "\n",
            "iteration 3900 :\n",
            "train rmse :  0.985818201326958\n",
            "validation rmse :  1.4560318455129746\n",
            "\n",
            "iteration 3950 :\n",
            "train rmse :  0.9855572466821977\n",
            "validation rmse :  1.4562399464353315\n",
            "\n",
            "iteration 4000 :\n",
            "train rmse :  0.9853092828978062\n",
            "validation rmse :  1.4564553644878933\n",
            "\n",
            "iteration 4050 :\n",
            "train rmse :  0.9850737187784893\n",
            "validation rmse :  1.4566776054143835\n",
            "\n",
            "iteration 4100 :\n",
            "train rmse :  0.984849993800871\n",
            "validation rmse :  1.4569062034908817\n",
            "\n",
            "iteration 4150 :\n",
            "train rmse :  0.9846375762608582\n",
            "validation rmse :  1.4571407197543689\n",
            "\n",
            "iteration 4200 :\n",
            "train rmse :  0.9844359615496627\n",
            "validation rmse :  1.4573807403524848\n",
            "\n",
            "iteration 4250 :\n",
            "train rmse :  0.9842446705483496\n",
            "validation rmse :  1.4576258750053646\n",
            "\n",
            "iteration 4300 :\n",
            "train rmse :  0.9840632481316689\n",
            "validation rmse :  1.4578757555711845\n",
            "\n",
            "iteration 4350 :\n",
            "train rmse :  0.9838912617727378\n",
            "validation rmse :  1.4581300347077302\n",
            "\n",
            "iteration 4400 :\n",
            "train rmse :  0.9837283002408699\n",
            "validation rmse :  1.4583883846229169\n",
            "\n",
            "iteration 4450 :\n",
            "train rmse :  0.9835739723855067\n",
            "validation rmse :  1.4586504959077737\n",
            "\n",
            "iteration 4500 :\n",
            "train rmse :  0.983427905999803\n",
            "validation rmse :  1.4589160764459088\n",
            "\n",
            "iteration 4550 :\n",
            "train rmse :  0.9832897467579595\n",
            "validation rmse :  1.459184850393951\n",
            "\n",
            "iteration 4600 :\n",
            "train rmse :  0.9831591572208824\n",
            "validation rmse :  1.4594565572279026\n",
            "\n",
            "iteration 4650 :\n",
            "train rmse :  0.9830358159052003\n",
            "validation rmse :  1.4597309508507204\n",
            "\n",
            "iteration 4700 :\n",
            "train rmse :  0.9829194164110721\n",
            "validation rmse :  1.4600077987568159\n",
            "\n",
            "iteration 4750 :\n",
            "train rmse :  0.9828096666045819\n",
            "validation rmse :  1.4602868812494945\n",
            "\n",
            "iteration 4800 :\n",
            "train rmse :  0.9827062878508622\n",
            "validation rmse :  1.4605679907076492\n",
            "\n",
            "iteration 4850 :\n",
            "train rmse :  0.9826090142943825\n",
            "validation rmse :  1.4608509308983184\n",
            "\n",
            "iteration 4900 :\n",
            "train rmse :  0.9825175921831276\n",
            "validation rmse :  1.4611355163319586\n",
            "\n",
            "iteration 4950 :\n",
            "train rmse :  0.9824317792336384\n",
            "validation rmse :  1.4614215716575254\n",
            "\n",
            "iteration 5000 :\n",
            "train rmse :  0.9823513440341258\n",
            "validation rmse :  1.4617089310946731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 0410 추가본 - 다른 레퍼런스 참고\n",
        "\n",
        " https://big-dream-world.tistory.com/69"
      ],
      "metadata": {
        "id": "CPqjK_cVuDSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 분해한 P, Q 행렬 임의값으로 생성\n",
        "2. P 행렬, Q 전치행렬 곱해서 예측행렬 생성, 실제 R 행렬과 차이 계산(R 행렬 내 존재하는 실제값들과의 차이) \n",
        "3. 차이 줄이는 방향으로 P, Q 행렬 업데이트\n",
        "4. 반복하며 근사화\n"
      ],
      "metadata": {
        "id": "W5BzceTVuMaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ** 상단 코드와의 차이  \n",
        "1. train_test_split 안함 - train값으로 안본 영화 평점 예측 목적\n",
        "2. 코드 간소화\n",
        "3. 추후 수정"
      ],
      "metadata": {
        "id": "xHGRPCiXu44Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L2X_H15Cv1f-",
        "outputId": "5c1a5820-d34e-4ac1-ac49-c4789ab2dacb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rating\n",
              "0      196      242       3\n",
              "1      186      302       3\n",
              "2       22      377       1\n",
              "3      244       51       2\n",
              "4      166      346       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d76cfc3-1562-4a28-bb05-c4551e43e4dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d76cfc3-1562-4a28-bb05-c4551e43e4dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d76cfc3-1562-4a28-bb05-c4551e43e4dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d76cfc3-1562-4a28-bb05-c4551e43e4dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df = rating.pivot(index = 'user_id', columns = 'item_id', values = 'rating')\n",
        "real_mat = rating_df.to_numpy()\n",
        "num_user, num_item = real_mat.shape"
      ],
      "metadata": {
        "id": "dvW7aKTExCjj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2iAa-1VLy_Z",
        "outputId": "b454ad6f-9efd-471b-fa3b-e0b3336c2174"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.,  3.,  4., ..., nan, nan, nan],\n",
              "       [ 4., nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       ...,\n",
              "       [ 5., nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       [nan,  5., nan, ..., nan, nan, nan]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_user, num_item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGgPKe2BzHiM",
        "outputId": "75814174-65e7-4e8f-a3ad-6503c275f2dc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P, Q 만들기\n",
        "K = 5\n",
        "P = np.random.normal(size=(num_user, K))\n",
        "Q = np.random.normal(size=(num_item, K))\n",
        "print(P.shape, Q.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5bi9fvR6ne1",
        "outputId": "d27bd760-ba5f-4bbe-d1b4-607abbbe50d5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(943, 5) (1682, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXhf-6YDQGiv",
        "outputId": "ff2933e0-fd18-4347-b69c-2eec6450cda7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.7245597 , -0.17150729,  1.37897079, -0.57885157,  0.71274853],\n",
              "       [ 0.3429683 , -0.52461838,  0.84040773,  0.45433431,  0.85646375],\n",
              "       [-0.17097968,  1.35593958,  0.22210508,  0.39740103,  1.66070481],\n",
              "       ...,\n",
              "       [ 0.18743347,  0.47139466, -1.22702874,  1.15932438,  1.34757507],\n",
              "       [ 1.95998917, -0.12734599, -0.46967133, -1.28144442,  0.27286509],\n",
              "       [-1.51475265,  1.76561731,  1.5217673 ,  0.47284183,  1.20171089]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pw08EepM83m",
        "outputId": "e129af53-5959-4207-ac2d-ebc7458d6295"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.562224926128023"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGeF8fDWQA8W",
        "outputId": "c571247d-9951-4166-a5f3-08cd39ed1447"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.41329918,  0.69361674, -0.48171511, -0.39338978, -0.55187523],\n",
              "       [-1.51055141, -1.36575973,  0.52120164, -1.7197342 , -0.08637016],\n",
              "       [ 2.26347044, -0.44428243, -1.52256167, -0.43193459, -0.80922582],\n",
              "       ...,\n",
              "       [-0.71402496,  0.1578051 , -1.36845653, -0.53815587,  0.74624167],\n",
              "       [-0.03222637,  0.13144685,  0.79017909,  0.00411883, -0.25427219],\n",
              "       [ 1.41135234,  0.64541051,  0.36789059, -1.94162847,  0.7914448 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtKPbjIkQIcT",
        "outputId": "11944097-93f8-4d9f-94ca-bc524a035d2a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.516657815914739"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_zeros = [(i, j, real_mat[i, j]) for i in range(num_user) for j in range(num_item) if real_mat[i, j] > 0]\n",
        "# 평점이 있는 user 위치, item 위치, rating 값 튜플로 묶어 리스트 내 저장\n",
        "non_zeros"
      ],
      "metadata": {
        "id": "yhGgHFHByQeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf8f3cc-a114-4c75-88a5-65390d8b682c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0, 5.0),\n",
              " (0, 1, 3.0),\n",
              " (0, 2, 4.0),\n",
              " (0, 3, 3.0),\n",
              " (0, 4, 3.0),\n",
              " (0, 5, 5.0),\n",
              " (0, 6, 4.0),\n",
              " (0, 7, 1.0),\n",
              " (0, 8, 5.0),\n",
              " (0, 9, 3.0),\n",
              " (0, 10, 2.0),\n",
              " (0, 11, 5.0),\n",
              " (0, 12, 5.0),\n",
              " (0, 13, 5.0),\n",
              " (0, 14, 5.0),\n",
              " (0, 15, 5.0),\n",
              " (0, 16, 3.0),\n",
              " (0, 17, 4.0),\n",
              " (0, 18, 5.0),\n",
              " (0, 19, 4.0),\n",
              " (0, 20, 1.0),\n",
              " (0, 21, 4.0),\n",
              " (0, 22, 4.0),\n",
              " (0, 23, 3.0),\n",
              " (0, 24, 4.0),\n",
              " (0, 25, 3.0),\n",
              " (0, 26, 2.0),\n",
              " (0, 27, 4.0),\n",
              " (0, 28, 1.0),\n",
              " (0, 29, 3.0),\n",
              " (0, 30, 3.0),\n",
              " (0, 31, 5.0),\n",
              " (0, 32, 4.0),\n",
              " (0, 33, 2.0),\n",
              " (0, 34, 1.0),\n",
              " (0, 35, 2.0),\n",
              " (0, 36, 2.0),\n",
              " (0, 37, 3.0),\n",
              " (0, 38, 4.0),\n",
              " (0, 39, 3.0),\n",
              " (0, 40, 2.0),\n",
              " (0, 41, 5.0),\n",
              " (0, 42, 4.0),\n",
              " (0, 43, 5.0),\n",
              " (0, 44, 5.0),\n",
              " (0, 45, 4.0),\n",
              " (0, 46, 4.0),\n",
              " (0, 47, 5.0),\n",
              " (0, 48, 3.0),\n",
              " (0, 49, 5.0),\n",
              " (0, 50, 4.0),\n",
              " (0, 51, 4.0),\n",
              " (0, 52, 3.0),\n",
              " (0, 53, 3.0),\n",
              " (0, 54, 5.0),\n",
              " (0, 55, 4.0),\n",
              " (0, 56, 5.0),\n",
              " (0, 57, 4.0),\n",
              " (0, 58, 5.0),\n",
              " (0, 59, 5.0),\n",
              " (0, 60, 4.0),\n",
              " (0, 61, 3.0),\n",
              " (0, 62, 2.0),\n",
              " (0, 63, 5.0),\n",
              " (0, 64, 4.0),\n",
              " (0, 65, 4.0),\n",
              " (0, 66, 3.0),\n",
              " (0, 67, 4.0),\n",
              " (0, 68, 3.0),\n",
              " (0, 69, 3.0),\n",
              " (0, 70, 3.0),\n",
              " (0, 71, 4.0),\n",
              " (0, 72, 3.0),\n",
              " (0, 73, 1.0),\n",
              " (0, 74, 4.0),\n",
              " (0, 75, 4.0),\n",
              " (0, 76, 4.0),\n",
              " (0, 77, 1.0),\n",
              " (0, 78, 4.0),\n",
              " (0, 79, 4.0),\n",
              " (0, 80, 5.0),\n",
              " (0, 81, 5.0),\n",
              " (0, 82, 3.0),\n",
              " (0, 83, 4.0),\n",
              " (0, 84, 3.0),\n",
              " (0, 85, 5.0),\n",
              " (0, 86, 5.0),\n",
              " (0, 87, 4.0),\n",
              " (0, 88, 5.0),\n",
              " (0, 89, 4.0),\n",
              " (0, 90, 5.0),\n",
              " (0, 91, 3.0),\n",
              " (0, 92, 5.0),\n",
              " (0, 93, 2.0),\n",
              " (0, 94, 4.0),\n",
              " (0, 95, 5.0),\n",
              " (0, 96, 3.0),\n",
              " (0, 97, 4.0),\n",
              " (0, 98, 3.0),\n",
              " (0, 99, 5.0),\n",
              " (0, 100, 2.0),\n",
              " (0, 101, 2.0),\n",
              " (0, 102, 1.0),\n",
              " (0, 103, 1.0),\n",
              " (0, 104, 2.0),\n",
              " (0, 105, 4.0),\n",
              " (0, 106, 4.0),\n",
              " (0, 107, 5.0),\n",
              " (0, 108, 5.0),\n",
              " (0, 109, 1.0),\n",
              " (0, 110, 5.0),\n",
              " (0, 111, 1.0),\n",
              " (0, 112, 5.0),\n",
              " (0, 113, 5.0),\n",
              " (0, 114, 5.0),\n",
              " (0, 115, 3.0),\n",
              " (0, 116, 3.0),\n",
              " (0, 117, 3.0),\n",
              " (0, 118, 5.0),\n",
              " (0, 119, 1.0),\n",
              " (0, 120, 4.0),\n",
              " (0, 121, 3.0),\n",
              " (0, 122, 4.0),\n",
              " (0, 123, 5.0),\n",
              " (0, 124, 3.0),\n",
              " (0, 125, 2.0),\n",
              " (0, 126, 5.0),\n",
              " (0, 127, 4.0),\n",
              " (0, 128, 5.0),\n",
              " (0, 129, 3.0),\n",
              " (0, 130, 1.0),\n",
              " (0, 131, 4.0),\n",
              " (0, 132, 4.0),\n",
              " (0, 133, 4.0),\n",
              " (0, 134, 4.0),\n",
              " (0, 135, 3.0),\n",
              " (0, 136, 5.0),\n",
              " (0, 137, 1.0),\n",
              " (0, 138, 3.0),\n",
              " (0, 139, 1.0),\n",
              " (0, 140, 3.0),\n",
              " (0, 141, 2.0),\n",
              " (0, 142, 1.0),\n",
              " (0, 143, 4.0),\n",
              " (0, 144, 2.0),\n",
              " (0, 145, 4.0),\n",
              " (0, 146, 3.0),\n",
              " (0, 147, 2.0),\n",
              " (0, 148, 2.0),\n",
              " (0, 149, 5.0),\n",
              " (0, 150, 4.0),\n",
              " (0, 151, 5.0),\n",
              " (0, 152, 3.0),\n",
              " (0, 153, 5.0),\n",
              " (0, 154, 2.0),\n",
              " (0, 155, 4.0),\n",
              " (0, 156, 4.0),\n",
              " (0, 157, 3.0),\n",
              " (0, 158, 3.0),\n",
              " (0, 159, 4.0),\n",
              " (0, 160, 4.0),\n",
              " (0, 161, 4.0),\n",
              " (0, 162, 4.0),\n",
              " (0, 163, 3.0),\n",
              " (0, 164, 5.0),\n",
              " (0, 165, 5.0),\n",
              " (0, 166, 2.0),\n",
              " (0, 167, 5.0),\n",
              " (0, 168, 5.0),\n",
              " (0, 169, 5.0),\n",
              " (0, 170, 5.0),\n",
              " (0, 171, 5.0),\n",
              " (0, 172, 5.0),\n",
              " (0, 173, 5.0),\n",
              " (0, 174, 5.0),\n",
              " (0, 175, 5.0),\n",
              " (0, 176, 5.0),\n",
              " (0, 177, 5.0),\n",
              " (0, 178, 3.0),\n",
              " (0, 179, 3.0),\n",
              " (0, 180, 5.0),\n",
              " (0, 181, 4.0),\n",
              " (0, 182, 5.0),\n",
              " (0, 183, 4.0),\n",
              " (0, 184, 4.0),\n",
              " (0, 185, 4.0),\n",
              " (0, 186, 4.0),\n",
              " (0, 187, 3.0),\n",
              " (0, 188, 3.0),\n",
              " (0, 189, 5.0),\n",
              " (0, 190, 5.0),\n",
              " (0, 191, 4.0),\n",
              " (0, 192, 4.0),\n",
              " (0, 193, 4.0),\n",
              " (0, 194, 5.0),\n",
              " (0, 195, 5.0),\n",
              " (0, 196, 5.0),\n",
              " (0, 197, 5.0),\n",
              " (0, 198, 4.0),\n",
              " (0, 199, 3.0),\n",
              " (0, 200, 3.0),\n",
              " (0, 201, 5.0),\n",
              " (0, 202, 4.0),\n",
              " (0, 203, 5.0),\n",
              " (0, 204, 3.0),\n",
              " (0, 205, 4.0),\n",
              " (0, 206, 5.0),\n",
              " (0, 207, 5.0),\n",
              " (0, 208, 4.0),\n",
              " (0, 209, 4.0),\n",
              " (0, 210, 3.0),\n",
              " (0, 211, 4.0),\n",
              " (0, 212, 2.0),\n",
              " (0, 213, 4.0),\n",
              " (0, 214, 3.0),\n",
              " (0, 215, 5.0),\n",
              " (0, 216, 3.0),\n",
              " (0, 217, 3.0),\n",
              " (0, 218, 1.0),\n",
              " (0, 219, 3.0),\n",
              " (0, 220, 5.0),\n",
              " (0, 221, 4.0),\n",
              " (0, 222, 5.0),\n",
              " (0, 223, 5.0),\n",
              " (0, 224, 2.0),\n",
              " (0, 225, 3.0),\n",
              " (0, 226, 4.0),\n",
              " (0, 227, 5.0),\n",
              " (0, 228, 4.0),\n",
              " (0, 229, 4.0),\n",
              " (0, 230, 1.0),\n",
              " (0, 231, 3.0),\n",
              " (0, 232, 2.0),\n",
              " (0, 233, 4.0),\n",
              " (0, 234, 5.0),\n",
              " (0, 235, 4.0),\n",
              " (0, 236, 2.0),\n",
              " (0, 237, 4.0),\n",
              " (0, 238, 4.0),\n",
              " (0, 239, 3.0),\n",
              " (0, 240, 4.0),\n",
              " (0, 241, 5.0),\n",
              " (0, 242, 1.0),\n",
              " (0, 243, 2.0),\n",
              " (0, 244, 2.0),\n",
              " (0, 245, 5.0),\n",
              " (0, 246, 1.0),\n",
              " (0, 247, 4.0),\n",
              " (0, 248, 4.0),\n",
              " (0, 249, 4.0),\n",
              " (0, 250, 4.0),\n",
              " (0, 251, 2.0),\n",
              " (0, 252, 5.0),\n",
              " (0, 253, 1.0),\n",
              " (0, 254, 2.0),\n",
              " (0, 255, 4.0),\n",
              " (0, 256, 4.0),\n",
              " (0, 257, 5.0),\n",
              " (0, 258, 1.0),\n",
              " (0, 259, 1.0),\n",
              " (0, 260, 1.0),\n",
              " (0, 261, 3.0),\n",
              " (0, 262, 1.0),\n",
              " (0, 263, 2.0),\n",
              " (0, 264, 4.0),\n",
              " (0, 265, 1.0),\n",
              " (0, 266, 4.0),\n",
              " (0, 267, 5.0),\n",
              " (0, 268, 5.0),\n",
              " (0, 269, 5.0),\n",
              " (0, 270, 2.0),\n",
              " (0, 271, 3.0),\n",
              " (1, 0, 4.0),\n",
              " (1, 9, 2.0),\n",
              " (1, 12, 4.0),\n",
              " (1, 13, 4.0),\n",
              " (1, 18, 3.0),\n",
              " (1, 24, 4.0),\n",
              " (1, 49, 5.0),\n",
              " (1, 99, 5.0),\n",
              " (1, 110, 4.0),\n",
              " (1, 126, 5.0),\n",
              " (1, 236, 4.0),\n",
              " (1, 241, 5.0),\n",
              " (1, 250, 5.0),\n",
              " (1, 254, 4.0),\n",
              " (1, 256, 4.0),\n",
              " (1, 257, 3.0),\n",
              " (1, 268, 4.0),\n",
              " (1, 271, 5.0),\n",
              " (1, 272, 4.0),\n",
              " (1, 273, 3.0),\n",
              " (1, 274, 5.0),\n",
              " (1, 275, 4.0),\n",
              " (1, 276, 4.0),\n",
              " (1, 277, 3.0),\n",
              " (1, 278, 4.0),\n",
              " (1, 279, 3.0),\n",
              " (1, 280, 3.0),\n",
              " (1, 281, 4.0),\n",
              " (1, 282, 5.0),\n",
              " (1, 283, 4.0),\n",
              " (1, 284, 5.0),\n",
              " (1, 285, 4.0),\n",
              " (1, 286, 3.0),\n",
              " (1, 287, 3.0),\n",
              " (1, 288, 3.0),\n",
              " (1, 289, 3.0),\n",
              " (1, 290, 3.0),\n",
              " (1, 291, 4.0),\n",
              " (1, 292, 4.0),\n",
              " (1, 293, 1.0),\n",
              " (1, 294, 4.0),\n",
              " (1, 295, 3.0),\n",
              " (1, 296, 4.0),\n",
              " (1, 297, 3.0),\n",
              " (1, 298, 4.0),\n",
              " (1, 299, 4.0),\n",
              " (1, 300, 4.0),\n",
              " (1, 301, 5.0),\n",
              " (1, 302, 4.0),\n",
              " (1, 303, 4.0),\n",
              " (1, 304, 3.0),\n",
              " (1, 305, 4.0),\n",
              " (1, 306, 3.0),\n",
              " (1, 307, 3.0),\n",
              " (1, 308, 1.0),\n",
              " (1, 309, 4.0),\n",
              " (1, 310, 5.0),\n",
              " (1, 311, 3.0),\n",
              " (1, 312, 5.0),\n",
              " (1, 313, 1.0),\n",
              " (1, 314, 1.0),\n",
              " (1, 315, 5.0),\n",
              " (2, 180, 4.0),\n",
              " (2, 244, 1.0),\n",
              " (2, 257, 2.0),\n",
              " (2, 259, 4.0),\n",
              " (2, 263, 2.0),\n",
              " (2, 267, 3.0),\n",
              " (2, 270, 3.0),\n",
              " (2, 271, 2.0),\n",
              " (2, 287, 2.0),\n",
              " (2, 293, 2.0),\n",
              " (2, 298, 3.0),\n",
              " (2, 299, 2.0),\n",
              " (2, 301, 2.0),\n",
              " (2, 302, 3.0),\n",
              " (2, 306, 3.0),\n",
              " (2, 316, 2.0),\n",
              " (2, 317, 4.0),\n",
              " (2, 318, 2.0),\n",
              " (2, 319, 5.0),\n",
              " (2, 320, 5.0),\n",
              " (2, 321, 3.0),\n",
              " (2, 322, 2.0),\n",
              " (2, 323, 2.0),\n",
              " (2, 324, 1.0),\n",
              " (2, 325, 2.0),\n",
              " (2, 326, 4.0),\n",
              " (2, 327, 5.0),\n",
              " (2, 328, 4.0),\n",
              " (2, 329, 2.0),\n",
              " (2, 330, 4.0),\n",
              " (2, 331, 1.0),\n",
              " (2, 332, 2.0),\n",
              " (2, 333, 3.0),\n",
              " (2, 334, 1.0),\n",
              " (2, 335, 1.0),\n",
              " (2, 336, 1.0),\n",
              " (2, 337, 2.0),\n",
              " (2, 338, 3.0),\n",
              " (2, 339, 5.0),\n",
              " (2, 340, 1.0),\n",
              " (2, 341, 4.0),\n",
              " (2, 342, 3.0),\n",
              " (2, 343, 4.0),\n",
              " (2, 344, 3.0),\n",
              " (2, 345, 5.0),\n",
              " (2, 346, 5.0),\n",
              " (2, 347, 4.0),\n",
              " (2, 348, 3.0),\n",
              " (2, 349, 3.0),\n",
              " (2, 350, 3.0),\n",
              " (2, 351, 2.0),\n",
              " (2, 352, 1.0),\n",
              " (2, 353, 3.0),\n",
              " (2, 354, 3.0),\n",
              " (3, 10, 4.0),\n",
              " (3, 49, 5.0),\n",
              " (3, 209, 3.0),\n",
              " (3, 257, 5.0),\n",
              " (3, 259, 4.0),\n",
              " (3, 263, 3.0),\n",
              " (3, 270, 4.0),\n",
              " (3, 287, 4.0),\n",
              " (3, 293, 5.0),\n",
              " (3, 299, 5.0),\n",
              " (3, 300, 5.0),\n",
              " (3, 302, 5.0),\n",
              " (3, 323, 5.0),\n",
              " (3, 326, 5.0),\n",
              " (3, 327, 3.0),\n",
              " (3, 328, 5.0),\n",
              " (3, 353, 5.0),\n",
              " (3, 355, 3.0),\n",
              " (3, 356, 4.0),\n",
              " (3, 357, 2.0),\n",
              " (3, 358, 5.0),\n",
              " (3, 359, 5.0),\n",
              " (3, 360, 5.0),\n",
              " (3, 361, 5.0),\n",
              " (4, 0, 4.0),\n",
              " (4, 1, 3.0),\n",
              " (4, 16, 4.0),\n",
              " (4, 20, 3.0),\n",
              " (4, 23, 4.0),\n",
              " (4, 24, 3.0),\n",
              " (4, 28, 4.0),\n",
              " (4, 39, 4.0),\n",
              " (4, 41, 5.0),\n",
              " (4, 49, 4.0),\n",
              " (4, 61, 4.0),\n",
              " (4, 62, 1.0),\n",
              " (4, 65, 1.0),\n",
              " (4, 68, 1.0),\n",
              " (4, 69, 4.0),\n",
              " (4, 78, 3.0),\n",
              " (4, 79, 2.0),\n",
              " (4, 88, 5.0),\n",
              " (4, 89, 3.0),\n",
              " (4, 93, 3.0),\n",
              " (4, 94, 4.0),\n",
              " (4, 97, 3.0),\n",
              " (4, 98, 3.0),\n",
              " (4, 99, 5.0),\n",
              " (4, 100, 5.0),\n",
              " (4, 101, 3.0),\n",
              " (4, 104, 3.0),\n",
              " (4, 108, 5.0),\n",
              " (4, 109, 1.0),\n",
              " (4, 120, 4.0),\n",
              " (4, 134, 4.0),\n",
              " (4, 138, 3.0),\n",
              " (4, 142, 3.0),\n",
              " (4, 143, 3.0),\n",
              " (4, 144, 1.0),\n",
              " (4, 150, 3.0),\n",
              " (4, 152, 5.0),\n",
              " (4, 153, 3.0),\n",
              " (4, 161, 1.0),\n",
              " (4, 162, 5.0),\n",
              " (4, 166, 2.0),\n",
              " (4, 167, 3.0),\n",
              " (4, 168, 5.0),\n",
              " (4, 171, 5.0),\n",
              " (4, 172, 4.0),\n",
              " (4, 173, 5.0),\n",
              " (4, 175, 3.0),\n",
              " (4, 180, 5.0),\n",
              " (4, 182, 4.0),\n",
              " (4, 184, 3.0),\n",
              " (4, 185, 5.0),\n",
              " (4, 188, 5.0),\n",
              " (4, 193, 4.0),\n",
              " (4, 199, 2.0),\n",
              " (4, 203, 4.0),\n",
              " (4, 207, 4.0),\n",
              " (4, 208, 5.0),\n",
              " (4, 209, 3.0),\n",
              " (4, 210, 4.0),\n",
              " (4, 213, 3.0),\n",
              " (4, 215, 1.0),\n",
              " (4, 218, 3.0),\n",
              " (4, 221, 4.0),\n",
              " (4, 224, 2.0),\n",
              " (4, 225, 3.0),\n",
              " (4, 226, 4.0),\n",
              " (4, 227, 5.0),\n",
              " (4, 228, 2.0),\n",
              " (4, 229, 3.0),\n",
              " (4, 230, 2.0),\n",
              " (4, 232, 4.0),\n",
              " (4, 233, 2.0),\n",
              " (4, 234, 4.0),\n",
              " (4, 238, 4.0),\n",
              " (4, 240, 1.0),\n",
              " (4, 242, 1.0),\n",
              " (4, 249, 3.0),\n",
              " (4, 256, 5.0),\n",
              " (4, 258, 1.0),\n",
              " (4, 266, 4.0),\n",
              " (4, 362, 3.0),\n",
              " (4, 363, 1.0),\n",
              " (4, 364, 1.0),\n",
              " (4, 365, 3.0),\n",
              " (4, 366, 3.0),\n",
              " (4, 367, 1.0),\n",
              " (4, 368, 1.0),\n",
              " (4, 369, 1.0),\n",
              " (4, 370, 1.0),\n",
              " (4, 371, 3.0),\n",
              " (4, 372, 3.0),\n",
              " (4, 373, 3.0),\n",
              " (4, 374, 3.0),\n",
              " (4, 375, 2.0),\n",
              " (4, 376, 1.0),\n",
              " (4, 377, 1.0),\n",
              " (4, 378, 3.0),\n",
              " (4, 379, 3.0),\n",
              " (4, 380, 1.0),\n",
              " (4, 381, 5.0),\n",
              " (4, 382, 3.0),\n",
              " (4, 383, 3.0),\n",
              " (4, 384, 4.0),\n",
              " (4, 385, 2.0),\n",
              " (4, 386, 3.0),\n",
              " (4, 387, 2.0),\n",
              " (4, 388, 1.0),\n",
              " (4, 389, 5.0),\n",
              " (4, 390, 4.0),\n",
              " (4, 391, 2.0),\n",
              " (4, 392, 2.0),\n",
              " (4, 393, 2.0),\n",
              " (4, 394, 2.0),\n",
              " (4, 395, 5.0),\n",
              " (4, 396, 2.0),\n",
              " (4, 397, 2.0),\n",
              " (4, 398, 3.0),\n",
              " (4, 399, 1.0),\n",
              " (4, 400, 5.0),\n",
              " (4, 401, 1.0),\n",
              " (4, 402, 3.0),\n",
              " (4, 403, 2.0),\n",
              " (4, 404, 3.0),\n",
              " (4, 405, 1.0),\n",
              " (4, 406, 3.0),\n",
              " (4, 407, 5.0),\n",
              " (4, 408, 2.0),\n",
              " (4, 409, 1.0),\n",
              " (4, 410, 1.0),\n",
              " (4, 411, 3.0),\n",
              " (4, 412, 3.0),\n",
              " (4, 413, 3.0),\n",
              " (4, 414, 1.0),\n",
              " (4, 415, 1.0),\n",
              " (4, 416, 3.0),\n",
              " (4, 417, 3.0),\n",
              " (4, 418, 3.0),\n",
              " (4, 419, 3.0),\n",
              " (4, 420, 1.0),\n",
              " (4, 421, 4.0),\n",
              " (4, 422, 4.0),\n",
              " (4, 423, 1.0),\n",
              " (4, 424, 2.0),\n",
              " (4, 425, 3.0),\n",
              " (4, 426, 3.0),\n",
              " (4, 427, 5.0),\n",
              " (4, 428, 3.0),\n",
              " (4, 429, 5.0),\n",
              " (4, 430, 3.0),\n",
              " (4, 431, 4.0),\n",
              " (4, 432, 5.0),\n",
              " (4, 433, 5.0),\n",
              " (4, 434, 4.0),\n",
              " (4, 435, 5.0),\n",
              " (4, 436, 1.0),\n",
              " (4, 437, 1.0),\n",
              " (4, 438, 1.0),\n",
              " (4, 439, 1.0),\n",
              " (4, 440, 1.0),\n",
              " (4, 441, 1.0),\n",
              " (4, 442, 4.0),\n",
              " (4, 443, 2.0),\n",
              " (4, 444, 3.0),\n",
              " (4, 445, 4.0),\n",
              " (4, 446, 3.0),\n",
              " (4, 447, 2.0),\n",
              " (4, 448, 2.0),\n",
              " (4, 449, 1.0),\n",
              " (4, 450, 1.0),\n",
              " (4, 451, 1.0),\n",
              " (4, 452, 1.0),\n",
              " (4, 453, 1.0),\n",
              " (4, 454, 4.0),\n",
              " (4, 455, 1.0),\n",
              " (4, 456, 1.0),\n",
              " (5, 0, 4.0),\n",
              " (5, 6, 2.0),\n",
              " (5, 7, 4.0),\n",
              " (5, 8, 4.0),\n",
              " (5, 11, 4.0),\n",
              " (5, 12, 2.0),\n",
              " (5, 13, 5.0),\n",
              " (5, 14, 3.0),\n",
              " (5, 18, 4.0),\n",
              " (5, 20, 3.0),\n",
              " (5, 21, 3.0),\n",
              " (5, 22, 4.0),\n",
              " (5, 27, 2.0),\n",
              " (5, 31, 4.0),\n",
              " (5, 46, 3.0),\n",
              " (5, 49, 4.0),\n",
              " (5, 55, 4.0),\n",
              " (5, 58, 5.0),\n",
              " (5, 63, 4.0),\n",
              " (5, 68, 3.0),\n",
              " (5, 69, 3.0),\n",
              " (5, 70, 4.0),\n",
              " (5, 78, 3.0),\n",
              " (5, 80, 4.0),\n",
              " (5, 85, 3.0),\n",
              " (5, 86, 4.0),\n",
              " (5, 88, 4.0),\n",
              " (5, 94, 2.0),\n",
              " (5, 97, 5.0),\n",
              " (5, 99, 5.0),\n",
              " (5, 110, 2.0),\n",
              " (5, 116, 2.0),\n",
              " (5, 123, 5.0),\n",
              " (5, 124, 3.0),\n",
              " (5, 126, 5.0),\n",
              " (5, 130, 5.0),\n",
              " (5, 131, 5.0),\n",
              " (5, 132, 4.0),\n",
              " (5, 133, 5.0),\n",
              " (5, 134, 5.0),\n",
              " (5, 135, 5.0),\n",
              " (5, 136, 5.0),\n",
              " (5, 142, 2.0),\n",
              " (5, 150, 3.0),\n",
              " (5, 152, 4.0),\n",
              " (5, 153, 3.0),\n",
              " (5, 155, 3.0),\n",
              " (5, 164, 5.0),\n",
              " (5, 165, 4.0),\n",
              " (5, 167, 4.0),\n",
              " (5, 168, 4.0),\n",
              " (5, 169, 4.0),\n",
              " (5, 172, 5.0),\n",
              " (5, 173, 4.0),\n",
              " (5, 174, 4.0),\n",
              " (5, 176, 4.0),\n",
              " (5, 177, 4.0),\n",
              " (5, 179, 4.0),\n",
              " (5, 181, 4.0),\n",
              " (5, 182, 4.0),\n",
              " (5, 184, 5.0),\n",
              " (5, 185, 4.0),\n",
              " (5, 186, 4.0),\n",
              " (5, 187, 3.0),\n",
              " (5, 188, 3.0),\n",
              " (5, 190, 4.0),\n",
              " (5, 191, 4.0),\n",
              " (5, 192, 3.0),\n",
              " (5, 193, 4.0),\n",
              " (5, 194, 4.0),\n",
              " (5, 196, 5.0),\n",
              " (5, 198, 4.0),\n",
              " (5, 199, 3.0),\n",
              " (5, 201, 3.0),\n",
              " (5, 202, 3.0),\n",
              " (5, 203, 3.0),\n",
              " (5, 204, 3.0),\n",
              " (5, 207, 4.0),\n",
              " (5, 208, 4.0),\n",
              " (5, 210, 5.0),\n",
              " (5, 212, 4.0),\n",
              " (5, 215, 5.0),\n",
              " (5, 220, 4.0),\n",
              " (5, 222, 4.0),\n",
              " (5, 236, 2.0),\n",
              " (5, 237, 5.0),\n",
              " (5, 241, 4.0),\n",
              " (5, 245, 3.0),\n",
              " (5, 247, 3.0),\n",
              " (5, 256, 2.0),\n",
              " (5, 257, 2.0),\n",
              " (5, 258, 1.0),\n",
              " (5, 260, 3.0),\n",
              " (5, 267, 3.0),\n",
              " (5, 268, 4.0),\n",
              " (5, 271, 4.0),\n",
              " (5, 273, 4.0),\n",
              " (5, 274, 4.0),\n",
              " (5, 275, 2.0),\n",
              " (5, 283, 2.0),\n",
              " (5, 284, 3.0),\n",
              " (5, 285, 2.0),\n",
              " (5, 292, 3.0),\n",
              " (5, 293, 2.0),\n",
              " (5, 296, 3.0),\n",
              " (5, 297, 3.0),\n",
              " (5, 300, 2.0),\n",
              " (5, 301, 4.0),\n",
              " (5, 302, 3.0),\n",
              " (5, 303, 4.0),\n",
              " (5, 305, 4.0),\n",
              " (5, 307, 3.0),\n",
              " (5, 308, 2.0),\n",
              " (5, 309, 2.0),\n",
              " (5, 316, 3.0),\n",
              " (5, 317, 4.0),\n",
              " (5, 320, 3.0),\n",
              " (5, 339, 2.0),\n",
              " (5, 356, 4.0),\n",
              " (5, 366, 2.0),\n",
              " (5, 404, 1.0),\n",
              " (5, 407, 4.0),\n",
              " (5, 409, 4.0),\n",
              " (5, 418, 4.0),\n",
              " (5, 422, 3.0),\n",
              " (5, 424, 3.0),\n",
              " (5, 426, 4.0),\n",
              " (5, 431, 4.0),\n",
              " (5, 434, 4.0),\n",
              " (5, 457, 1.0),\n",
              " (5, 458, 2.0),\n",
              " (5, 459, 2.0),\n",
              " (5, 460, 4.0),\n",
              " (5, 461, 5.0),\n",
              " (5, 462, 4.0),\n",
              " (5, 463, 2.0),\n",
              " (5, 464, 1.0),\n",
              " (5, 465, 4.0),\n",
              " (5, 466, 4.0),\n",
              " (5, 467, 3.0),\n",
              " (5, 468, 5.0),\n",
              " (5, 469, 3.0),\n",
              " (5, 470, 2.0),\n",
              " (5, 471, 1.0),\n",
              " (5, 472, 2.0),\n",
              " (5, 473, 5.0),\n",
              " (5, 474, 5.0),\n",
              " (5, 475, 1.0),\n",
              " (5, 476, 1.0),\n",
              " (5, 477, 4.0),\n",
              " (5, 478, 5.0),\n",
              " (5, 479, 4.0),\n",
              " (5, 480, 5.0),\n",
              " (5, 481, 4.0),\n",
              " (5, 482, 5.0),\n",
              " (5, 483, 5.0),\n",
              " (5, 484, 5.0),\n",
              " (5, 485, 4.0),\n",
              " (5, 486, 5.0),\n",
              " (5, 487, 5.0),\n",
              " (5, 488, 5.0),\n",
              " (5, 489, 5.0),\n",
              " (5, 490, 4.0),\n",
              " (5, 491, 5.0),\n",
              " (5, 492, 5.0),\n",
              " (5, 493, 4.0),\n",
              " (5, 494, 4.0),\n",
              " (5, 495, 4.0),\n",
              " (5, 496, 4.0),\n",
              " (5, 497, 4.0),\n",
              " (5, 498, 4.0),\n",
              " (5, 499, 4.0),\n",
              " (5, 500, 5.0),\n",
              " (5, 501, 4.0),\n",
              " (5, 502, 3.0),\n",
              " (5, 503, 3.0),\n",
              " (5, 504, 4.0),\n",
              " (5, 505, 4.0),\n",
              " (5, 506, 4.0),\n",
              " (5, 507, 3.0),\n",
              " (5, 508, 4.0),\n",
              " (5, 509, 4.0),\n",
              " (5, 510, 5.0),\n",
              " (5, 511, 4.0),\n",
              " (5, 512, 4.0),\n",
              " (5, 513, 5.0),\n",
              " (5, 514, 4.0),\n",
              " (5, 515, 4.0),\n",
              " (5, 516, 4.0),\n",
              " (5, 517, 3.0),\n",
              " (5, 518, 5.0),\n",
              " (5, 519, 4.0),\n",
              " (5, 520, 4.0),\n",
              " (5, 521, 5.0),\n",
              " (5, 522, 5.0),\n",
              " (5, 523, 3.0),\n",
              " (5, 524, 5.0),\n",
              " (5, 525, 3.0),\n",
              " (5, 526, 4.0),\n",
              " (5, 527, 4.0),\n",
              " (5, 528, 4.0),\n",
              " (5, 529, 4.0),\n",
              " (5, 530, 4.0),\n",
              " (5, 531, 3.0),\n",
              " (5, 532, 4.0),\n",
              " (5, 533, 4.0),\n",
              " (5, 534, 2.0),\n",
              " (5, 535, 4.0),\n",
              " (5, 536, 4.0),\n",
              " (5, 537, 2.0),\n",
              " (5, 538, 2.0),\n",
              " (6, 3, 5.0),\n",
              " (6, 6, 5.0),\n",
              " (6, 7, 5.0),\n",
              " (6, 8, 5.0),\n",
              " (6, 9, 4.0),\n",
              " (6, 10, 3.0),\n",
              " (6, 11, 5.0),\n",
              " (6, 21, 5.0),\n",
              " (6, 22, 3.0),\n",
              " (6, 24, 3.0),\n",
              " (6, 26, 4.0),\n",
              " (6, 27, 5.0),\n",
              " (6, 28, 3.0),\n",
              " (6, 30, 4.0),\n",
              " (6, 31, 4.0),\n",
              " (6, 38, 5.0),\n",
              " (6, 43, 5.0),\n",
              " (6, 46, 5.0),\n",
              " (6, 49, 5.0),\n",
              " (6, 50, 2.0),\n",
              " (6, 51, 4.0),\n",
              " (6, 52, 5.0),\n",
              " (6, 53, 3.0),\n",
              " (6, 55, 5.0),\n",
              " (6, 61, 3.0),\n",
              " (6, 63, 5.0),\n",
              " (6, 67, 4.0),\n",
              " (6, 68, 5.0),\n",
              " (6, 69, 1.0),\n",
              " (6, 70, 5.0),\n",
              " (6, 71, 5.0),\n",
              " (6, 72, 3.0),\n",
              " (6, 76, 5.0),\n",
              " (6, 77, 3.0),\n",
              " (6, 78, 4.0),\n",
              " (6, 79, 4.0),\n",
              " (6, 80, 5.0),\n",
              " (6, 81, 3.0),\n",
              " (6, 85, 4.0),\n",
              " (6, 88, 5.0),\n",
              " (6, 89, 3.0),\n",
              " (6, 90, 3.0),\n",
              " (6, 91, 5.0),\n",
              " (6, 92, 5.0),\n",
              " (6, 95, 5.0),\n",
              " (6, 96, 5.0),\n",
              " (6, 97, 4.0),\n",
              " (6, 98, 5.0),\n",
              " (6, 99, 5.0),\n",
              " (6, 100, 5.0),\n",
              " (6, 105, 4.0),\n",
              " (6, 117, 2.0),\n",
              " (6, 120, 5.0),\n",
              " (6, 124, 4.0),\n",
              " (6, 125, 3.0),\n",
              " (6, 126, 5.0),\n",
              " (6, 130, 5.0),\n",
              " (6, 131, 5.0),\n",
              " (6, 132, 5.0),\n",
              " (6, 133, 4.0),\n",
              " (6, 134, 5.0),\n",
              " (6, 135, 5.0),\n",
              " (6, 138, 3.0),\n",
              " (6, 139, 5.0),\n",
              " (6, 140, 5.0),\n",
              " (6, 141, 3.0),\n",
              " (6, 142, 3.0),\n",
              " (6, 143, 5.0),\n",
              " (6, 144, 1.0),\n",
              " (6, 150, 4.0),\n",
              " (6, 151, 4.0),\n",
              " (6, 152, 5.0),\n",
              " (6, 153, 5.0),\n",
              " (6, 155, 5.0),\n",
              " (6, 156, 5.0),\n",
              " (6, 160, 3.0),\n",
              " (6, 161, 5.0),\n",
              " (6, 162, 4.0),\n",
              " (6, 163, 5.0),\n",
              " (6, 165, 3.0),\n",
              " (6, 167, 5.0),\n",
              " (6, 170, 3.0),\n",
              " (6, 171, 4.0),\n",
              " (6, 172, 5.0),\n",
              " (6, 173, 5.0),\n",
              " (6, 174, 5.0),\n",
              " (6, 175, 3.0),\n",
              " (6, 176, 4.0),\n",
              " (6, 177, 4.0),\n",
              " (6, 178, 5.0),\n",
              " (6, 179, 5.0),\n",
              " (6, 180, 3.0),\n",
              " (6, 181, 4.0),\n",
              " (6, 182, 4.0),\n",
              " (6, 184, 5.0),\n",
              " (6, 185, 4.0),\n",
              " (6, 186, 4.0),\n",
              " (6, 187, 5.0),\n",
              " (6, 189, 5.0),\n",
              " (6, 190, 5.0),\n",
              " (6, 191, 4.0),\n",
              " (6, 192, 5.0),\n",
              " (6, 193, 5.0),\n",
              " (6, 194, 5.0),\n",
              " (6, 195, 5.0),\n",
              " (6, 196, 4.0),\n",
              " (6, 197, 3.0),\n",
              " (6, 198, 5.0),\n",
              " (6, 199, 5.0),\n",
              " (6, 200, 2.0),\n",
              " (6, 201, 3.0),\n",
              " (6, 202, 5.0),\n",
              " (6, 203, 5.0),\n",
              " (6, 204, 5.0),\n",
              " (6, 206, 4.0),\n",
              " (6, 207, 5.0),\n",
              " (6, 209, 4.0),\n",
              " (6, 210, 5.0),\n",
              " (6, 211, 1.0),\n",
              " (6, 212, 3.0),\n",
              " (6, 213, 5.0),\n",
              " (6, 214, 4.0),\n",
              " (6, 215, 4.0),\n",
              " (6, 216, 4.0),\n",
              " (6, 218, 1.0),\n",
              " (6, 222, 5.0),\n",
              " (6, 225, 5.0),\n",
              " (6, 226, 3.0),\n",
              " (6, 227, 4.0),\n",
              " (6, 228, 3.0),\n",
              " (6, 229, 3.0),\n",
              " (6, 230, 3.0),\n",
              " (6, 231, 3.0),\n",
              " (6, 233, 5.0),\n",
              " (6, 236, 5.0),\n",
              " (6, 237, 5.0),\n",
              " (6, 240, 4.0),\n",
              " (6, 257, 4.0),\n",
              " (6, 258, 3.0),\n",
              " (6, 259, 1.0),\n",
              " (6, 263, 4.0),\n",
              " (6, 264, 5.0),\n",
              " (6, 265, 4.0),\n",
              " (6, 267, 3.0),\n",
              " (6, 268, 3.0),\n",
              " (6, 272, 3.0),\n",
              " (6, 274, 4.0),\n",
              " (6, 280, 3.0),\n",
              " (6, 284, 5.0),\n",
              " (6, 285, 4.0),\n",
              " (6, 287, 4.0),\n",
              " (6, 293, 1.0),\n",
              " (6, 299, 4.0),\n",
              " (6, 306, 5.0),\n",
              " (6, 308, 3.0),\n",
              " (6, 316, 4.0),\n",
              " (6, 317, 5.0),\n",
              " (6, 323, 1.0),\n",
              " (6, 333, 5.0),\n",
              " (6, 340, 3.0),\n",
              " (6, 355, 4.0),\n",
              " (6, 356, 5.0),\n",
              " (6, 364, 4.0),\n",
              " (6, 366, 5.0),\n",
              " (6, 377, 5.0),\n",
              " (6, 378, 4.0),\n",
              " (6, 379, 4.0),\n",
              " (6, 381, 4.0),\n",
              " (6, 383, 3.0),\n",
              " (6, 384, 5.0),\n",
              " (6, 385, 4.0),\n",
              " (6, 386, 3.0),\n",
              " (6, 388, 4.0),\n",
              " (6, 390, 3.0),\n",
              " (6, 392, 4.0),\n",
              " (6, 395, 4.0),\n",
              " (6, 398, 4.0),\n",
              " (6, 400, 4.0),\n",
              " (6, 401, 5.0),\n",
              " (6, 402, 4.0),\n",
              " (6, 403, 5.0),\n",
              " (6, 404, 3.0),\n",
              " (6, 414, 2.0),\n",
              " (6, 415, 5.0),\n",
              " (6, 416, 3.0),\n",
              " (6, 417, 4.0),\n",
              " (6, 418, 3.0),\n",
              " (6, 419, 5.0),\n",
              " (6, 420, 3.0),\n",
              " (6, 422, 5.0),\n",
              " (6, 426, 5.0),\n",
              " (6, 427, 5.0),\n",
              " (6, 428, 5.0),\n",
              " (6, 429, 3.0),\n",
              " (6, 430, 4.0),\n",
              " (6, 431, 4.0),\n",
              " (6, 432, 5.0),\n",
              " (6, 433, 4.0),\n",
              " (6, 434, 5.0),\n",
              " (6, 435, 5.0),\n",
              " (6, 439, 1.0),\n",
              " (6, 440, 2.0),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(real_mat, P, Q, non_zeros):\n",
        "  # real_df = 실제 유저 아이템 행렬\n",
        "  # P, Q = 잠재요인, user와 item으로 분해된 잠재행렬, 이걸로 예측 행렬 생성\n",
        "  # non_null = real_df 내 null값 아니었던 것(real_df 만으로 함수 내 해결할 수 있을것으로 보이나, 저장해서 반복 계산 시 효율성 재고)\n",
        "  error = 0\n",
        "  pred_mat = np.dot(P, Q.T)\n",
        "  # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "  user_non_zero_index = [non_zero[0] for non_zero in non_zeros]\n",
        "  item_non_zero_index = [non_zero[1] for non_zero in non_zeros]\n",
        "  real_mat_non_zero = real_mat[user_non_zero_index, item_non_zero_index]\n",
        "  pred_mat_non_zero = pred_mat[user_non_zero_index, item_non_zero_index]\n",
        "\n",
        "  mse = mean_squared_error(real_mat_non_zero, pred_mat_non_zero)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "UZNfhGz0vrOC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_rmse(real_mat, P,Q, non_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjtJKG8eEKcC",
        "outputId": "244202f6-5801-40b1-d3a6-21820bf5899e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.322673748594236"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**비용 함수 생략 잠재 행렬(P, Q) 내 벡터(Pu, Qi) 업데이트 식**  \n",
        "  \n",
        "* Rui = 실제 행렬의 (u, i) 값  \n",
        "* R^ui = 예측 행렬의 (u, i) 값  \n",
        "* Eui = (u, i)위치의 실제행렬 값 예측행렬 값 차이 \n",
        "\n",
        "  * $e_{ui}=r_{ui}-p_uq_i^T$\n",
        "* Gradient\n",
        "  * $\\frac {\\partial L}{\\partial p_u} = \\frac {\\partial(r_{ui}-p_uq_i^T)^2}{\\partial p_u} + \\frac {\\partial\\lambda||p_u||^2_2}{\\partial p_u} = -2(r_{ui}-p_uq_i^T)q_i+2\\lambda p_u = -2(e_{ui}q_i-\\lambda p_u)$\n",
        "    * 기존 LOSS에서 $p_u$에 대해 편미분을 진행해 필요없는 $q_i$항을 모두 지우고 계산하면 $-2(e_{ui}q_i-\\lambda p_u)$가 남게 됨.\n",
        "  * Gradient 반대로 $p_u, q_i$ 업데이트\n",
        "    * $p_u ← p_u +\\eta \\cdot(e_{ui}q_i - \\lambda p_u)$\n",
        "    * $q_i ← q_i +\\eta \\cdot(e_{ui}p_u - \\lambda q_i)$\n",
        "  \n",
        "* Pu(new) = Pu + 학습률 * (Eui * Qi - lambda(L2 정규화 계수) * Pu)  \n",
        "* Qi(new) = Qi + 학습률 * (Eui * Pu - lambda(L2 정규화 계수) * Qi)\n"
      ],
      "metadata": {
        "id": "371acnId1GCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iteration = 200\n",
        "learning_rate = 0.01\n",
        "lmbda = 0.01"
      ],
      "metadata": {
        "id": "R7HxbXnM00m2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(iteration):\n",
        "  for i, j, Rij in non_zeros:\n",
        "    # 실제 값과 예측 값의 차이인 오류 값 구함\n",
        "    Eij = Rij - np.dot(P[i, :], Q[j, :].T)\n",
        "    # 벡터 업데이트 :Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i, :] = P[i, :] + learning_rate *(Eij* Q[j, :] - lmbda* P[i, :])\n",
        "    Q[j, :] = Q[j, :] + learning_rate *(Eij* P[i, :] - lmbda* Q[j, :])\n",
        "  rmse = get_rmse(real_mat, P, Q, non_zeros)\n",
        "  if (iter+1) % 10 == 0:\n",
        "    print('iteration num : ', iter+1, \" rmse : \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdJlOoFx48a6",
        "outputId": "11af77d0-f2ff-43b1-d057-8ada8cc66337"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration num :  10  rmse :  0.9304000224406472\n",
            "iteration num :  20  rmse :  0.8973367593290096\n",
            "iteration num :  30  rmse :  0.8742098451235227\n",
            "iteration num :  40  rmse :  0.8588092266280087\n",
            "iteration num :  50  rmse :  0.8482139777007578\n",
            "iteration num :  60  rmse :  0.8404999970164897\n",
            "iteration num :  70  rmse :  0.8345785877012425\n",
            "iteration num :  80  rmse :  0.8299031066508002\n",
            "iteration num :  90  rmse :  0.8261782702293161\n",
            "iteration num :  100  rmse :  0.8232022435305887\n",
            "iteration num :  110  rmse :  0.8208128155091534\n",
            "iteration num :  120  rmse :  0.8188766302747367\n",
            "iteration num :  130  rmse :  0.8172878486769516\n",
            "iteration num :  140  rmse :  0.8159663912323314\n",
            "iteration num :  150  rmse :  0.8148539357478874\n",
            "iteration num :  160  rmse :  0.813908480896653\n",
            "iteration num :  170  rmse :  0.8130991924266986\n",
            "iteration num :  180  rmse :  0.8124024989379751\n",
            "iteration num :  190  rmse :  0.8117995736650115\n",
            "iteration num :  200  rmse :  0.8112749180016177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이후 내용은 추천시스템.  \n",
        "test train 나눠서 검증이 아니라 최대한 오차를 낮춘 다음 유저가 안 본 영화 중 예측 평점 높은 순대로 추천하는 시스템.  \n",
        "그렇다면 과적합 문제가 발생하지 않을까?  \n"
      ],
      "metadata": {
        "id": "MR__DdtPT8tk"
      }
    }
  ]
}