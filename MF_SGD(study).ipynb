{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CP2J/cp2j/blob/ACJ-9-MF-SGD-/MF_SGD(study).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BJGCsWgzp_Z4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "rating = pd.read_csv('/content/drive/MyDrive/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUBUOdF6VWbV",
        "outputId": "ce4bdca7-bbcd-4c6d-d271-451680b93eb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MF-SGD (Matrix Factorization - Stochastic Gradient Descent)\n",
        "* SVD에서 쓰인 행렬분해를 이용, 확률적 경사하강 기법으로 오차를 줄이는 방향으로 학습한다.\n",
        "* SVD의 행렬분해에서는 null값이 존재하면 안되기에 평균값, 최빈값 등을 사용했으나 여기서는 랜덤값 지정 후 오차를 줄이는 방향으로 학습.\n",
        "* 결국 데이터가 sparse 할 수록 임의값에 의존하던 이전 모델들에 비해 성능이 더 잘 나오게 된다.\n",
        "\n",
        "# 0410 추가본 - 다른 레퍼런스 참고\n",
        " https://big-dream-world.tistory.com/69"
      ],
      "metadata": {
        "id": "CPqjK_cVuDSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 분해한 P, Q 행렬 임의값으로 생성\n",
        "2. P 행렬, Q 전치행렬 곱해서 예측행렬 생성, 실제 R 행렬과 차이 계산(R 행렬 내 존재하는 실제값들과의 차이) \n",
        "3. 차이 줄이는 방향으로 P, Q 행렬 업데이트\n",
        "4. 반복하며 근사화\n"
      ],
      "metadata": {
        "id": "W5BzceTVuMaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ** 상단 코드와의 차이  \n",
        "1. train_test_split 안함 - train값으로 안본 영화 평점 예측 목적\n",
        "2. 코드 간소화\n",
        "3. 추후 수정"
      ],
      "metadata": {
        "id": "xHGRPCiXu44Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L2X_H15Cv1f-",
        "outputId": "d755150d-c3e2-4cd6-dae0-6f57c030b974"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rating  timestamp\n",
              "0      196      242       3  881250949\n",
              "1      186      302       3  891717742\n",
              "2       22      377       1  878887116\n",
              "3      244       51       2  880606923\n",
              "4      166      346       1  886397596"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74279755-4071-4d22-812c-656040c53ec5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74279755-4071-4d22-812c-656040c53ec5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74279755-4071-4d22-812c-656040c53ec5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74279755-4071-4d22-812c-656040c53ec5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df = rating.pivot(index = 'user_id', columns = 'item_id', values = 'rating')\n",
        "real_mat = rating_df.to_numpy()\n",
        "num_user, num_item = real_mat.shape"
      ],
      "metadata": {
        "id": "dvW7aKTExCjj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2iAa-1VLy_Z",
        "outputId": "8c8f98bd-d9ce-4d59-d97d-a51c2f9d8320"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.,  3.,  4., ..., nan, nan, nan],\n",
              "       [ 4., nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       ...,\n",
              "       [ 5., nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       [nan,  5., nan, ..., nan, nan, nan]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_user, num_item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGgPKe2BzHiM",
        "outputId": "8767cad0-f0a7-476b-be11-adaca5632cec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P, Q 만들기\n",
        "K = 5\n",
        "np.random.seed(1)\n",
        "P = np.random.normal(scale=1./K, size=(num_user, K))\n",
        "Q = np.random.normal(scale=1./K, size=(num_item, K))\n",
        "print(P.shape, Q.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5bi9fvR6ne1",
        "outputId": "32d95aa9-06cd-49c0-bd2c-4852001d2f86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(943, 5) (1682, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXhf-6YDQGiv",
        "outputId": "27d85531-35f7-4ccb-ca5a-fec211fff1e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.32486907, -0.12235128, -0.10563435, -0.21459372,  0.17308153],\n",
              "       [-0.46030774,  0.34896235, -0.15224138,  0.06380782, -0.04987408],\n",
              "       [ 0.29242159, -0.41202814, -0.06448344, -0.07681087,  0.22675389],\n",
              "       ...,\n",
              "       [ 0.25492871, -0.05039558,  0.097754  ,  0.07813002,  0.15870667],\n",
              "       [-0.00779446,  0.21716811, -0.10508495,  0.21014734,  0.24452006],\n",
              "       [-0.0066753 ,  0.09060358,  0.01855727,  0.119657  ,  0.13527794]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pw08EepM83m",
        "outputId": "8db9dc0b-ce60-428e-90af-a03c24d34c52"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7917205408075927"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGeF8fDWQA8W",
        "outputId": "b9c0820a-31a8-46f3-85d7-79500799d9b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.05209434, -0.04480388,  0.16500092,  0.09246273,  0.47655322],\n",
              "       [-0.21540172,  0.38926981,  0.08383212,  0.161059  , -0.12298153],\n",
              "       [-0.08035176,  0.07262364,  0.00623031, -0.27591379,  0.01610528],\n",
              "       ...,\n",
              "       [ 0.00449204,  0.00646432, -0.3573115 ,  0.21257792, -0.12423349],\n",
              "       [ 0.01938678,  0.09546832,  0.06378416, -0.04559171, -0.2420766 ],\n",
              "       [ 0.23471571, -0.58564795, -0.0952186 , -0.26388873, -0.07425806]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtKPbjIkQIcT",
        "outputId": "7d8a1d96-bba2-4afe-c7a7-b9db50e94466"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8053698089094756"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_zeros = [(i, j, real_mat[i, j]) for i in range(num_user) for j in range(num_item) if real_mat[i, j] > 0]\n",
        "# 평점이 있는 user 위치, item 위치, rating 값 튜플로 묶어 리스트 내 저장\n",
        "non_zeros"
      ],
      "metadata": {
        "id": "yhGgHFHByQeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9976008-ed7c-4734-d727-88591dd31cbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0, 5.0),\n",
              " (0, 1, 3.0),\n",
              " (0, 2, 4.0),\n",
              " (0, 3, 3.0),\n",
              " (0, 4, 3.0),\n",
              " (0, 5, 5.0),\n",
              " (0, 6, 4.0),\n",
              " (0, 7, 1.0),\n",
              " (0, 8, 5.0),\n",
              " (0, 9, 3.0),\n",
              " (0, 10, 2.0),\n",
              " (0, 11, 5.0),\n",
              " (0, 12, 5.0),\n",
              " (0, 13, 5.0),\n",
              " (0, 14, 5.0),\n",
              " (0, 15, 5.0),\n",
              " (0, 16, 3.0),\n",
              " (0, 17, 4.0),\n",
              " (0, 18, 5.0),\n",
              " (0, 19, 4.0),\n",
              " (0, 20, 1.0),\n",
              " (0, 21, 4.0),\n",
              " (0, 22, 4.0),\n",
              " (0, 23, 3.0),\n",
              " (0, 24, 4.0),\n",
              " (0, 25, 3.0),\n",
              " (0, 26, 2.0),\n",
              " (0, 27, 4.0),\n",
              " (0, 28, 1.0),\n",
              " (0, 29, 3.0),\n",
              " (0, 30, 3.0),\n",
              " (0, 31, 5.0),\n",
              " (0, 32, 4.0),\n",
              " (0, 33, 2.0),\n",
              " (0, 34, 1.0),\n",
              " (0, 35, 2.0),\n",
              " (0, 36, 2.0),\n",
              " (0, 37, 3.0),\n",
              " (0, 38, 4.0),\n",
              " (0, 39, 3.0),\n",
              " (0, 40, 2.0),\n",
              " (0, 41, 5.0),\n",
              " (0, 42, 4.0),\n",
              " (0, 43, 5.0),\n",
              " (0, 44, 5.0),\n",
              " (0, 45, 4.0),\n",
              " (0, 46, 4.0),\n",
              " (0, 47, 5.0),\n",
              " (0, 48, 3.0),\n",
              " (0, 49, 5.0),\n",
              " (0, 50, 4.0),\n",
              " (0, 51, 4.0),\n",
              " (0, 52, 3.0),\n",
              " (0, 53, 3.0),\n",
              " (0, 54, 5.0),\n",
              " (0, 55, 4.0),\n",
              " (0, 56, 5.0),\n",
              " (0, 57, 4.0),\n",
              " (0, 58, 5.0),\n",
              " (0, 59, 5.0),\n",
              " (0, 60, 4.0),\n",
              " (0, 61, 3.0),\n",
              " (0, 62, 2.0),\n",
              " (0, 63, 5.0),\n",
              " (0, 64, 4.0),\n",
              " (0, 65, 4.0),\n",
              " (0, 66, 3.0),\n",
              " (0, 67, 4.0),\n",
              " (0, 68, 3.0),\n",
              " (0, 69, 3.0),\n",
              " (0, 70, 3.0),\n",
              " (0, 71, 4.0),\n",
              " (0, 72, 3.0),\n",
              " (0, 73, 1.0),\n",
              " (0, 74, 4.0),\n",
              " (0, 75, 4.0),\n",
              " (0, 76, 4.0),\n",
              " (0, 77, 1.0),\n",
              " (0, 78, 4.0),\n",
              " (0, 79, 4.0),\n",
              " (0, 80, 5.0),\n",
              " (0, 81, 5.0),\n",
              " (0, 82, 3.0),\n",
              " (0, 83, 4.0),\n",
              " (0, 84, 3.0),\n",
              " (0, 85, 5.0),\n",
              " (0, 86, 5.0),\n",
              " (0, 87, 4.0),\n",
              " (0, 88, 5.0),\n",
              " (0, 89, 4.0),\n",
              " (0, 90, 5.0),\n",
              " (0, 91, 3.0),\n",
              " (0, 92, 5.0),\n",
              " (0, 93, 2.0),\n",
              " (0, 94, 4.0),\n",
              " (0, 95, 5.0),\n",
              " (0, 96, 3.0),\n",
              " (0, 97, 4.0),\n",
              " (0, 98, 3.0),\n",
              " (0, 99, 5.0),\n",
              " (0, 100, 2.0),\n",
              " (0, 101, 2.0),\n",
              " (0, 102, 1.0),\n",
              " (0, 103, 1.0),\n",
              " (0, 104, 2.0),\n",
              " (0, 105, 4.0),\n",
              " (0, 106, 4.0),\n",
              " (0, 107, 5.0),\n",
              " (0, 108, 5.0),\n",
              " (0, 109, 1.0),\n",
              " (0, 110, 5.0),\n",
              " (0, 111, 1.0),\n",
              " (0, 112, 5.0),\n",
              " (0, 113, 5.0),\n",
              " (0, 114, 5.0),\n",
              " (0, 115, 3.0),\n",
              " (0, 116, 3.0),\n",
              " (0, 117, 3.0),\n",
              " (0, 118, 5.0),\n",
              " (0, 119, 1.0),\n",
              " (0, 120, 4.0),\n",
              " (0, 121, 3.0),\n",
              " (0, 122, 4.0),\n",
              " (0, 123, 5.0),\n",
              " (0, 124, 3.0),\n",
              " (0, 125, 2.0),\n",
              " (0, 126, 5.0),\n",
              " (0, 127, 4.0),\n",
              " (0, 128, 5.0),\n",
              " (0, 129, 3.0),\n",
              " (0, 130, 1.0),\n",
              " (0, 131, 4.0),\n",
              " (0, 132, 4.0),\n",
              " (0, 133, 4.0),\n",
              " (0, 134, 4.0),\n",
              " (0, 135, 3.0),\n",
              " (0, 136, 5.0),\n",
              " (0, 137, 1.0),\n",
              " (0, 138, 3.0),\n",
              " (0, 139, 1.0),\n",
              " (0, 140, 3.0),\n",
              " (0, 141, 2.0),\n",
              " (0, 142, 1.0),\n",
              " (0, 143, 4.0),\n",
              " (0, 144, 2.0),\n",
              " (0, 145, 4.0),\n",
              " (0, 146, 3.0),\n",
              " (0, 147, 2.0),\n",
              " (0, 148, 2.0),\n",
              " (0, 149, 5.0),\n",
              " (0, 150, 4.0),\n",
              " (0, 151, 5.0),\n",
              " (0, 152, 3.0),\n",
              " (0, 153, 5.0),\n",
              " (0, 154, 2.0),\n",
              " (0, 155, 4.0),\n",
              " (0, 156, 4.0),\n",
              " (0, 157, 3.0),\n",
              " (0, 158, 3.0),\n",
              " (0, 159, 4.0),\n",
              " (0, 160, 4.0),\n",
              " (0, 161, 4.0),\n",
              " (0, 162, 4.0),\n",
              " (0, 163, 3.0),\n",
              " (0, 164, 5.0),\n",
              " (0, 165, 5.0),\n",
              " (0, 166, 2.0),\n",
              " (0, 167, 5.0),\n",
              " (0, 168, 5.0),\n",
              " (0, 169, 5.0),\n",
              " (0, 170, 5.0),\n",
              " (0, 171, 5.0),\n",
              " (0, 172, 5.0),\n",
              " (0, 173, 5.0),\n",
              " (0, 174, 5.0),\n",
              " (0, 175, 5.0),\n",
              " (0, 176, 5.0),\n",
              " (0, 177, 5.0),\n",
              " (0, 178, 3.0),\n",
              " (0, 179, 3.0),\n",
              " (0, 180, 5.0),\n",
              " (0, 181, 4.0),\n",
              " (0, 182, 5.0),\n",
              " (0, 183, 4.0),\n",
              " (0, 184, 4.0),\n",
              " (0, 185, 4.0),\n",
              " (0, 186, 4.0),\n",
              " (0, 187, 3.0),\n",
              " (0, 188, 3.0),\n",
              " (0, 189, 5.0),\n",
              " (0, 190, 5.0),\n",
              " (0, 191, 4.0),\n",
              " (0, 192, 4.0),\n",
              " (0, 193, 4.0),\n",
              " (0, 194, 5.0),\n",
              " (0, 195, 5.0),\n",
              " (0, 196, 5.0),\n",
              " (0, 197, 5.0),\n",
              " (0, 198, 4.0),\n",
              " (0, 199, 3.0),\n",
              " (0, 200, 3.0),\n",
              " (0, 201, 5.0),\n",
              " (0, 202, 4.0),\n",
              " (0, 203, 5.0),\n",
              " (0, 204, 3.0),\n",
              " (0, 205, 4.0),\n",
              " (0, 206, 5.0),\n",
              " (0, 207, 5.0),\n",
              " (0, 208, 4.0),\n",
              " (0, 209, 4.0),\n",
              " (0, 210, 3.0),\n",
              " (0, 211, 4.0),\n",
              " (0, 212, 2.0),\n",
              " (0, 213, 4.0),\n",
              " (0, 214, 3.0),\n",
              " (0, 215, 5.0),\n",
              " (0, 216, 3.0),\n",
              " (0, 217, 3.0),\n",
              " (0, 218, 1.0),\n",
              " (0, 219, 3.0),\n",
              " (0, 220, 5.0),\n",
              " (0, 221, 4.0),\n",
              " (0, 222, 5.0),\n",
              " (0, 223, 5.0),\n",
              " (0, 224, 2.0),\n",
              " (0, 225, 3.0),\n",
              " (0, 226, 4.0),\n",
              " (0, 227, 5.0),\n",
              " (0, 228, 4.0),\n",
              " (0, 229, 4.0),\n",
              " (0, 230, 1.0),\n",
              " (0, 231, 3.0),\n",
              " (0, 232, 2.0),\n",
              " (0, 233, 4.0),\n",
              " (0, 234, 5.0),\n",
              " (0, 235, 4.0),\n",
              " (0, 236, 2.0),\n",
              " (0, 237, 4.0),\n",
              " (0, 238, 4.0),\n",
              " (0, 239, 3.0),\n",
              " (0, 240, 4.0),\n",
              " (0, 241, 5.0),\n",
              " (0, 242, 1.0),\n",
              " (0, 243, 2.0),\n",
              " (0, 244, 2.0),\n",
              " (0, 245, 5.0),\n",
              " (0, 246, 1.0),\n",
              " (0, 247, 4.0),\n",
              " (0, 248, 4.0),\n",
              " (0, 249, 4.0),\n",
              " (0, 250, 4.0),\n",
              " (0, 251, 2.0),\n",
              " (0, 252, 5.0),\n",
              " (0, 253, 1.0),\n",
              " (0, 254, 2.0),\n",
              " (0, 255, 4.0),\n",
              " (0, 256, 4.0),\n",
              " (0, 257, 5.0),\n",
              " (0, 258, 1.0),\n",
              " (0, 259, 1.0),\n",
              " (0, 260, 1.0),\n",
              " (0, 261, 3.0),\n",
              " (0, 262, 1.0),\n",
              " (0, 263, 2.0),\n",
              " (0, 264, 4.0),\n",
              " (0, 265, 1.0),\n",
              " (0, 266, 4.0),\n",
              " (0, 267, 5.0),\n",
              " (0, 268, 5.0),\n",
              " (0, 269, 5.0),\n",
              " (0, 270, 2.0),\n",
              " (0, 271, 3.0),\n",
              " (1, 0, 4.0),\n",
              " (1, 9, 2.0),\n",
              " (1, 12, 4.0),\n",
              " (1, 13, 4.0),\n",
              " (1, 18, 3.0),\n",
              " (1, 24, 4.0),\n",
              " (1, 49, 5.0),\n",
              " (1, 99, 5.0),\n",
              " (1, 110, 4.0),\n",
              " (1, 126, 5.0),\n",
              " (1, 236, 4.0),\n",
              " (1, 241, 5.0),\n",
              " (1, 250, 5.0),\n",
              " (1, 254, 4.0),\n",
              " (1, 256, 4.0),\n",
              " (1, 257, 3.0),\n",
              " (1, 268, 4.0),\n",
              " (1, 271, 5.0),\n",
              " (1, 272, 4.0),\n",
              " (1, 273, 3.0),\n",
              " (1, 274, 5.0),\n",
              " (1, 275, 4.0),\n",
              " (1, 276, 4.0),\n",
              " (1, 277, 3.0),\n",
              " (1, 278, 4.0),\n",
              " (1, 279, 3.0),\n",
              " (1, 280, 3.0),\n",
              " (1, 281, 4.0),\n",
              " (1, 282, 5.0),\n",
              " (1, 283, 4.0),\n",
              " (1, 284, 5.0),\n",
              " (1, 285, 4.0),\n",
              " (1, 286, 3.0),\n",
              " (1, 287, 3.0),\n",
              " (1, 288, 3.0),\n",
              " (1, 289, 3.0),\n",
              " (1, 290, 3.0),\n",
              " (1, 291, 4.0),\n",
              " (1, 292, 4.0),\n",
              " (1, 293, 1.0),\n",
              " (1, 294, 4.0),\n",
              " (1, 295, 3.0),\n",
              " (1, 296, 4.0),\n",
              " (1, 297, 3.0),\n",
              " (1, 298, 4.0),\n",
              " (1, 299, 4.0),\n",
              " (1, 300, 4.0),\n",
              " (1, 301, 5.0),\n",
              " (1, 302, 4.0),\n",
              " (1, 303, 4.0),\n",
              " (1, 304, 3.0),\n",
              " (1, 305, 4.0),\n",
              " (1, 306, 3.0),\n",
              " (1, 307, 3.0),\n",
              " (1, 308, 1.0),\n",
              " (1, 309, 4.0),\n",
              " (1, 310, 5.0),\n",
              " (1, 311, 3.0),\n",
              " (1, 312, 5.0),\n",
              " (1, 313, 1.0),\n",
              " (1, 314, 1.0),\n",
              " (1, 315, 5.0),\n",
              " (2, 180, 4.0),\n",
              " (2, 244, 1.0),\n",
              " (2, 257, 2.0),\n",
              " (2, 259, 4.0),\n",
              " (2, 263, 2.0),\n",
              " (2, 267, 3.0),\n",
              " (2, 270, 3.0),\n",
              " (2, 271, 2.0),\n",
              " (2, 287, 2.0),\n",
              " (2, 293, 2.0),\n",
              " (2, 298, 3.0),\n",
              " (2, 299, 2.0),\n",
              " (2, 301, 2.0),\n",
              " (2, 302, 3.0),\n",
              " (2, 306, 3.0),\n",
              " (2, 316, 2.0),\n",
              " (2, 317, 4.0),\n",
              " (2, 318, 2.0),\n",
              " (2, 319, 5.0),\n",
              " (2, 320, 5.0),\n",
              " (2, 321, 3.0),\n",
              " (2, 322, 2.0),\n",
              " (2, 323, 2.0),\n",
              " (2, 324, 1.0),\n",
              " (2, 325, 2.0),\n",
              " (2, 326, 4.0),\n",
              " (2, 327, 5.0),\n",
              " (2, 328, 4.0),\n",
              " (2, 329, 2.0),\n",
              " (2, 330, 4.0),\n",
              " (2, 331, 1.0),\n",
              " (2, 332, 2.0),\n",
              " (2, 333, 3.0),\n",
              " (2, 334, 1.0),\n",
              " (2, 335, 1.0),\n",
              " (2, 336, 1.0),\n",
              " (2, 337, 2.0),\n",
              " (2, 338, 3.0),\n",
              " (2, 339, 5.0),\n",
              " (2, 340, 1.0),\n",
              " (2, 341, 4.0),\n",
              " (2, 342, 3.0),\n",
              " (2, 343, 4.0),\n",
              " (2, 344, 3.0),\n",
              " (2, 345, 5.0),\n",
              " (2, 346, 5.0),\n",
              " (2, 347, 4.0),\n",
              " (2, 348, 3.0),\n",
              " (2, 349, 3.0),\n",
              " (2, 350, 3.0),\n",
              " (2, 351, 2.0),\n",
              " (2, 352, 1.0),\n",
              " (2, 353, 3.0),\n",
              " (2, 354, 3.0),\n",
              " (3, 10, 4.0),\n",
              " (3, 49, 5.0),\n",
              " (3, 209, 3.0),\n",
              " (3, 257, 5.0),\n",
              " (3, 259, 4.0),\n",
              " (3, 263, 3.0),\n",
              " (3, 270, 4.0),\n",
              " (3, 287, 4.0),\n",
              " (3, 293, 5.0),\n",
              " (3, 299, 5.0),\n",
              " (3, 300, 5.0),\n",
              " (3, 302, 5.0),\n",
              " (3, 323, 5.0),\n",
              " (3, 326, 5.0),\n",
              " (3, 327, 3.0),\n",
              " (3, 328, 5.0),\n",
              " (3, 353, 5.0),\n",
              " (3, 355, 3.0),\n",
              " (3, 356, 4.0),\n",
              " (3, 357, 2.0),\n",
              " (3, 358, 5.0),\n",
              " (3, 359, 5.0),\n",
              " (3, 360, 5.0),\n",
              " (3, 361, 5.0),\n",
              " (4, 0, 4.0),\n",
              " (4, 1, 3.0),\n",
              " (4, 16, 4.0),\n",
              " (4, 20, 3.0),\n",
              " (4, 23, 4.0),\n",
              " (4, 24, 3.0),\n",
              " (4, 28, 4.0),\n",
              " (4, 39, 4.0),\n",
              " (4, 41, 5.0),\n",
              " (4, 49, 4.0),\n",
              " (4, 61, 4.0),\n",
              " (4, 62, 1.0),\n",
              " (4, 65, 1.0),\n",
              " (4, 68, 1.0),\n",
              " (4, 69, 4.0),\n",
              " (4, 78, 3.0),\n",
              " (4, 79, 2.0),\n",
              " (4, 88, 5.0),\n",
              " (4, 89, 3.0),\n",
              " (4, 93, 3.0),\n",
              " (4, 94, 4.0),\n",
              " (4, 97, 3.0),\n",
              " (4, 98, 3.0),\n",
              " (4, 99, 5.0),\n",
              " (4, 100, 5.0),\n",
              " (4, 101, 3.0),\n",
              " (4, 104, 3.0),\n",
              " (4, 108, 5.0),\n",
              " (4, 109, 1.0),\n",
              " (4, 120, 4.0),\n",
              " (4, 134, 4.0),\n",
              " (4, 138, 3.0),\n",
              " (4, 142, 3.0),\n",
              " (4, 143, 3.0),\n",
              " (4, 144, 1.0),\n",
              " (4, 150, 3.0),\n",
              " (4, 152, 5.0),\n",
              " (4, 153, 3.0),\n",
              " (4, 161, 1.0),\n",
              " (4, 162, 5.0),\n",
              " (4, 166, 2.0),\n",
              " (4, 167, 3.0),\n",
              " (4, 168, 5.0),\n",
              " (4, 171, 5.0),\n",
              " (4, 172, 4.0),\n",
              " (4, 173, 5.0),\n",
              " (4, 175, 3.0),\n",
              " (4, 180, 5.0),\n",
              " (4, 182, 4.0),\n",
              " (4, 184, 3.0),\n",
              " (4, 185, 5.0),\n",
              " (4, 188, 5.0),\n",
              " (4, 193, 4.0),\n",
              " (4, 199, 2.0),\n",
              " (4, 203, 4.0),\n",
              " (4, 207, 4.0),\n",
              " (4, 208, 5.0),\n",
              " (4, 209, 3.0),\n",
              " (4, 210, 4.0),\n",
              " (4, 213, 3.0),\n",
              " (4, 215, 1.0),\n",
              " (4, 218, 3.0),\n",
              " (4, 221, 4.0),\n",
              " (4, 224, 2.0),\n",
              " (4, 225, 3.0),\n",
              " (4, 226, 4.0),\n",
              " (4, 227, 5.0),\n",
              " (4, 228, 2.0),\n",
              " (4, 229, 3.0),\n",
              " (4, 230, 2.0),\n",
              " (4, 232, 4.0),\n",
              " (4, 233, 2.0),\n",
              " (4, 234, 4.0),\n",
              " (4, 238, 4.0),\n",
              " (4, 240, 1.0),\n",
              " (4, 242, 1.0),\n",
              " (4, 249, 3.0),\n",
              " (4, 256, 5.0),\n",
              " (4, 258, 1.0),\n",
              " (4, 266, 4.0),\n",
              " (4, 362, 3.0),\n",
              " (4, 363, 1.0),\n",
              " (4, 364, 1.0),\n",
              " (4, 365, 3.0),\n",
              " (4, 366, 3.0),\n",
              " (4, 367, 1.0),\n",
              " (4, 368, 1.0),\n",
              " (4, 369, 1.0),\n",
              " (4, 370, 1.0),\n",
              " (4, 371, 3.0),\n",
              " (4, 372, 3.0),\n",
              " (4, 373, 3.0),\n",
              " (4, 374, 3.0),\n",
              " (4, 375, 2.0),\n",
              " (4, 376, 1.0),\n",
              " (4, 377, 1.0),\n",
              " (4, 378, 3.0),\n",
              " (4, 379, 3.0),\n",
              " (4, 380, 1.0),\n",
              " (4, 381, 5.0),\n",
              " (4, 382, 3.0),\n",
              " (4, 383, 3.0),\n",
              " (4, 384, 4.0),\n",
              " (4, 385, 2.0),\n",
              " (4, 386, 3.0),\n",
              " (4, 387, 2.0),\n",
              " (4, 388, 1.0),\n",
              " (4, 389, 5.0),\n",
              " (4, 390, 4.0),\n",
              " (4, 391, 2.0),\n",
              " (4, 392, 2.0),\n",
              " (4, 393, 2.0),\n",
              " (4, 394, 2.0),\n",
              " (4, 395, 5.0),\n",
              " (4, 396, 2.0),\n",
              " (4, 397, 2.0),\n",
              " (4, 398, 3.0),\n",
              " (4, 399, 1.0),\n",
              " (4, 400, 5.0),\n",
              " (4, 401, 1.0),\n",
              " (4, 402, 3.0),\n",
              " (4, 403, 2.0),\n",
              " (4, 404, 3.0),\n",
              " (4, 405, 1.0),\n",
              " (4, 406, 3.0),\n",
              " (4, 407, 5.0),\n",
              " (4, 408, 2.0),\n",
              " (4, 409, 1.0),\n",
              " (4, 410, 1.0),\n",
              " (4, 411, 3.0),\n",
              " (4, 412, 3.0),\n",
              " (4, 413, 3.0),\n",
              " (4, 414, 1.0),\n",
              " (4, 415, 1.0),\n",
              " (4, 416, 3.0),\n",
              " (4, 417, 3.0),\n",
              " (4, 418, 3.0),\n",
              " (4, 419, 3.0),\n",
              " (4, 420, 1.0),\n",
              " (4, 421, 4.0),\n",
              " (4, 422, 4.0),\n",
              " (4, 423, 1.0),\n",
              " (4, 424, 2.0),\n",
              " (4, 425, 3.0),\n",
              " (4, 426, 3.0),\n",
              " (4, 427, 5.0),\n",
              " (4, 428, 3.0),\n",
              " (4, 429, 5.0),\n",
              " (4, 430, 3.0),\n",
              " (4, 431, 4.0),\n",
              " (4, 432, 5.0),\n",
              " (4, 433, 5.0),\n",
              " (4, 434, 4.0),\n",
              " (4, 435, 5.0),\n",
              " (4, 436, 1.0),\n",
              " (4, 437, 1.0),\n",
              " (4, 438, 1.0),\n",
              " (4, 439, 1.0),\n",
              " (4, 440, 1.0),\n",
              " (4, 441, 1.0),\n",
              " (4, 442, 4.0),\n",
              " (4, 443, 2.0),\n",
              " (4, 444, 3.0),\n",
              " (4, 445, 4.0),\n",
              " (4, 446, 3.0),\n",
              " (4, 447, 2.0),\n",
              " (4, 448, 2.0),\n",
              " (4, 449, 1.0),\n",
              " (4, 450, 1.0),\n",
              " (4, 451, 1.0),\n",
              " (4, 452, 1.0),\n",
              " (4, 453, 1.0),\n",
              " (4, 454, 4.0),\n",
              " (4, 455, 1.0),\n",
              " (4, 456, 1.0),\n",
              " (5, 0, 4.0),\n",
              " (5, 6, 2.0),\n",
              " (5, 7, 4.0),\n",
              " (5, 8, 4.0),\n",
              " (5, 11, 4.0),\n",
              " (5, 12, 2.0),\n",
              " (5, 13, 5.0),\n",
              " (5, 14, 3.0),\n",
              " (5, 18, 4.0),\n",
              " (5, 20, 3.0),\n",
              " (5, 21, 3.0),\n",
              " (5, 22, 4.0),\n",
              " (5, 27, 2.0),\n",
              " (5, 31, 4.0),\n",
              " (5, 46, 3.0),\n",
              " (5, 49, 4.0),\n",
              " (5, 55, 4.0),\n",
              " (5, 58, 5.0),\n",
              " (5, 63, 4.0),\n",
              " (5, 68, 3.0),\n",
              " (5, 69, 3.0),\n",
              " (5, 70, 4.0),\n",
              " (5, 78, 3.0),\n",
              " (5, 80, 4.0),\n",
              " (5, 85, 3.0),\n",
              " (5, 86, 4.0),\n",
              " (5, 88, 4.0),\n",
              " (5, 94, 2.0),\n",
              " (5, 97, 5.0),\n",
              " (5, 99, 5.0),\n",
              " (5, 110, 2.0),\n",
              " (5, 116, 2.0),\n",
              " (5, 123, 5.0),\n",
              " (5, 124, 3.0),\n",
              " (5, 126, 5.0),\n",
              " (5, 130, 5.0),\n",
              " (5, 131, 5.0),\n",
              " (5, 132, 4.0),\n",
              " (5, 133, 5.0),\n",
              " (5, 134, 5.0),\n",
              " (5, 135, 5.0),\n",
              " (5, 136, 5.0),\n",
              " (5, 142, 2.0),\n",
              " (5, 150, 3.0),\n",
              " (5, 152, 4.0),\n",
              " (5, 153, 3.0),\n",
              " (5, 155, 3.0),\n",
              " (5, 164, 5.0),\n",
              " (5, 165, 4.0),\n",
              " (5, 167, 4.0),\n",
              " (5, 168, 4.0),\n",
              " (5, 169, 4.0),\n",
              " (5, 172, 5.0),\n",
              " (5, 173, 4.0),\n",
              " (5, 174, 4.0),\n",
              " (5, 176, 4.0),\n",
              " (5, 177, 4.0),\n",
              " (5, 179, 4.0),\n",
              " (5, 181, 4.0),\n",
              " (5, 182, 4.0),\n",
              " (5, 184, 5.0),\n",
              " (5, 185, 4.0),\n",
              " (5, 186, 4.0),\n",
              " (5, 187, 3.0),\n",
              " (5, 188, 3.0),\n",
              " (5, 190, 4.0),\n",
              " (5, 191, 4.0),\n",
              " (5, 192, 3.0),\n",
              " (5, 193, 4.0),\n",
              " (5, 194, 4.0),\n",
              " (5, 196, 5.0),\n",
              " (5, 198, 4.0),\n",
              " (5, 199, 3.0),\n",
              " (5, 201, 3.0),\n",
              " (5, 202, 3.0),\n",
              " (5, 203, 3.0),\n",
              " (5, 204, 3.0),\n",
              " (5, 207, 4.0),\n",
              " (5, 208, 4.0),\n",
              " (5, 210, 5.0),\n",
              " (5, 212, 4.0),\n",
              " (5, 215, 5.0),\n",
              " (5, 220, 4.0),\n",
              " (5, 222, 4.0),\n",
              " (5, 236, 2.0),\n",
              " (5, 237, 5.0),\n",
              " (5, 241, 4.0),\n",
              " (5, 245, 3.0),\n",
              " (5, 247, 3.0),\n",
              " (5, 256, 2.0),\n",
              " (5, 257, 2.0),\n",
              " (5, 258, 1.0),\n",
              " (5, 260, 3.0),\n",
              " (5, 267, 3.0),\n",
              " (5, 268, 4.0),\n",
              " (5, 271, 4.0),\n",
              " (5, 273, 4.0),\n",
              " (5, 274, 4.0),\n",
              " (5, 275, 2.0),\n",
              " (5, 283, 2.0),\n",
              " (5, 284, 3.0),\n",
              " (5, 285, 2.0),\n",
              " (5, 292, 3.0),\n",
              " (5, 293, 2.0),\n",
              " (5, 296, 3.0),\n",
              " (5, 297, 3.0),\n",
              " (5, 300, 2.0),\n",
              " (5, 301, 4.0),\n",
              " (5, 302, 3.0),\n",
              " (5, 303, 4.0),\n",
              " (5, 305, 4.0),\n",
              " (5, 307, 3.0),\n",
              " (5, 308, 2.0),\n",
              " (5, 309, 2.0),\n",
              " (5, 316, 3.0),\n",
              " (5, 317, 4.0),\n",
              " (5, 320, 3.0),\n",
              " (5, 339, 2.0),\n",
              " (5, 356, 4.0),\n",
              " (5, 366, 2.0),\n",
              " (5, 404, 1.0),\n",
              " (5, 407, 4.0),\n",
              " (5, 409, 4.0),\n",
              " (5, 418, 4.0),\n",
              " (5, 422, 3.0),\n",
              " (5, 424, 3.0),\n",
              " (5, 426, 4.0),\n",
              " (5, 431, 4.0),\n",
              " (5, 434, 4.0),\n",
              " (5, 457, 1.0),\n",
              " (5, 458, 2.0),\n",
              " (5, 459, 2.0),\n",
              " (5, 460, 4.0),\n",
              " (5, 461, 5.0),\n",
              " (5, 462, 4.0),\n",
              " (5, 463, 2.0),\n",
              " (5, 464, 1.0),\n",
              " (5, 465, 4.0),\n",
              " (5, 466, 4.0),\n",
              " (5, 467, 3.0),\n",
              " (5, 468, 5.0),\n",
              " (5, 469, 3.0),\n",
              " (5, 470, 2.0),\n",
              " (5, 471, 1.0),\n",
              " (5, 472, 2.0),\n",
              " (5, 473, 5.0),\n",
              " (5, 474, 5.0),\n",
              " (5, 475, 1.0),\n",
              " (5, 476, 1.0),\n",
              " (5, 477, 4.0),\n",
              " (5, 478, 5.0),\n",
              " (5, 479, 4.0),\n",
              " (5, 480, 5.0),\n",
              " (5, 481, 4.0),\n",
              " (5, 482, 5.0),\n",
              " (5, 483, 5.0),\n",
              " (5, 484, 5.0),\n",
              " (5, 485, 4.0),\n",
              " (5, 486, 5.0),\n",
              " (5, 487, 5.0),\n",
              " (5, 488, 5.0),\n",
              " (5, 489, 5.0),\n",
              " (5, 490, 4.0),\n",
              " (5, 491, 5.0),\n",
              " (5, 492, 5.0),\n",
              " (5, 493, 4.0),\n",
              " (5, 494, 4.0),\n",
              " (5, 495, 4.0),\n",
              " (5, 496, 4.0),\n",
              " (5, 497, 4.0),\n",
              " (5, 498, 4.0),\n",
              " (5, 499, 4.0),\n",
              " (5, 500, 5.0),\n",
              " (5, 501, 4.0),\n",
              " (5, 502, 3.0),\n",
              " (5, 503, 3.0),\n",
              " (5, 504, 4.0),\n",
              " (5, 505, 4.0),\n",
              " (5, 506, 4.0),\n",
              " (5, 507, 3.0),\n",
              " (5, 508, 4.0),\n",
              " (5, 509, 4.0),\n",
              " (5, 510, 5.0),\n",
              " (5, 511, 4.0),\n",
              " (5, 512, 4.0),\n",
              " (5, 513, 5.0),\n",
              " (5, 514, 4.0),\n",
              " (5, 515, 4.0),\n",
              " (5, 516, 4.0),\n",
              " (5, 517, 3.0),\n",
              " (5, 518, 5.0),\n",
              " (5, 519, 4.0),\n",
              " (5, 520, 4.0),\n",
              " (5, 521, 5.0),\n",
              " (5, 522, 5.0),\n",
              " (5, 523, 3.0),\n",
              " (5, 524, 5.0),\n",
              " (5, 525, 3.0),\n",
              " (5, 526, 4.0),\n",
              " (5, 527, 4.0),\n",
              " (5, 528, 4.0),\n",
              " (5, 529, 4.0),\n",
              " (5, 530, 4.0),\n",
              " (5, 531, 3.0),\n",
              " (5, 532, 4.0),\n",
              " (5, 533, 4.0),\n",
              " (5, 534, 2.0),\n",
              " (5, 535, 4.0),\n",
              " (5, 536, 4.0),\n",
              " (5, 537, 2.0),\n",
              " (5, 538, 2.0),\n",
              " (6, 3, 5.0),\n",
              " (6, 6, 5.0),\n",
              " (6, 7, 5.0),\n",
              " (6, 8, 5.0),\n",
              " (6, 9, 4.0),\n",
              " (6, 10, 3.0),\n",
              " (6, 11, 5.0),\n",
              " (6, 21, 5.0),\n",
              " (6, 22, 3.0),\n",
              " (6, 24, 3.0),\n",
              " (6, 26, 4.0),\n",
              " (6, 27, 5.0),\n",
              " (6, 28, 3.0),\n",
              " (6, 30, 4.0),\n",
              " (6, 31, 4.0),\n",
              " (6, 38, 5.0),\n",
              " (6, 43, 5.0),\n",
              " (6, 46, 5.0),\n",
              " (6, 49, 5.0),\n",
              " (6, 50, 2.0),\n",
              " (6, 51, 4.0),\n",
              " (6, 52, 5.0),\n",
              " (6, 53, 3.0),\n",
              " (6, 55, 5.0),\n",
              " (6, 61, 3.0),\n",
              " (6, 63, 5.0),\n",
              " (6, 67, 4.0),\n",
              " (6, 68, 5.0),\n",
              " (6, 69, 1.0),\n",
              " (6, 70, 5.0),\n",
              " (6, 71, 5.0),\n",
              " (6, 72, 3.0),\n",
              " (6, 76, 5.0),\n",
              " (6, 77, 3.0),\n",
              " (6, 78, 4.0),\n",
              " (6, 79, 4.0),\n",
              " (6, 80, 5.0),\n",
              " (6, 81, 3.0),\n",
              " (6, 85, 4.0),\n",
              " (6, 88, 5.0),\n",
              " (6, 89, 3.0),\n",
              " (6, 90, 3.0),\n",
              " (6, 91, 5.0),\n",
              " (6, 92, 5.0),\n",
              " (6, 95, 5.0),\n",
              " (6, 96, 5.0),\n",
              " (6, 97, 4.0),\n",
              " (6, 98, 5.0),\n",
              " (6, 99, 5.0),\n",
              " (6, 100, 5.0),\n",
              " (6, 105, 4.0),\n",
              " (6, 117, 2.0),\n",
              " (6, 120, 5.0),\n",
              " (6, 124, 4.0),\n",
              " (6, 125, 3.0),\n",
              " (6, 126, 5.0),\n",
              " (6, 130, 5.0),\n",
              " (6, 131, 5.0),\n",
              " (6, 132, 5.0),\n",
              " (6, 133, 4.0),\n",
              " (6, 134, 5.0),\n",
              " (6, 135, 5.0),\n",
              " (6, 138, 3.0),\n",
              " (6, 139, 5.0),\n",
              " (6, 140, 5.0),\n",
              " (6, 141, 3.0),\n",
              " (6, 142, 3.0),\n",
              " (6, 143, 5.0),\n",
              " (6, 144, 1.0),\n",
              " (6, 150, 4.0),\n",
              " (6, 151, 4.0),\n",
              " (6, 152, 5.0),\n",
              " (6, 153, 5.0),\n",
              " (6, 155, 5.0),\n",
              " (6, 156, 5.0),\n",
              " (6, 160, 3.0),\n",
              " (6, 161, 5.0),\n",
              " (6, 162, 4.0),\n",
              " (6, 163, 5.0),\n",
              " (6, 165, 3.0),\n",
              " (6, 167, 5.0),\n",
              " (6, 170, 3.0),\n",
              " (6, 171, 4.0),\n",
              " (6, 172, 5.0),\n",
              " (6, 173, 5.0),\n",
              " (6, 174, 5.0),\n",
              " (6, 175, 3.0),\n",
              " (6, 176, 4.0),\n",
              " (6, 177, 4.0),\n",
              " (6, 178, 5.0),\n",
              " (6, 179, 5.0),\n",
              " (6, 180, 3.0),\n",
              " (6, 181, 4.0),\n",
              " (6, 182, 4.0),\n",
              " (6, 184, 5.0),\n",
              " (6, 185, 4.0),\n",
              " (6, 186, 4.0),\n",
              " (6, 187, 5.0),\n",
              " (6, 189, 5.0),\n",
              " (6, 190, 5.0),\n",
              " (6, 191, 4.0),\n",
              " (6, 192, 5.0),\n",
              " (6, 193, 5.0),\n",
              " (6, 194, 5.0),\n",
              " (6, 195, 5.0),\n",
              " (6, 196, 4.0),\n",
              " (6, 197, 3.0),\n",
              " (6, 198, 5.0),\n",
              " (6, 199, 5.0),\n",
              " (6, 200, 2.0),\n",
              " (6, 201, 3.0),\n",
              " (6, 202, 5.0),\n",
              " (6, 203, 5.0),\n",
              " (6, 204, 5.0),\n",
              " (6, 206, 4.0),\n",
              " (6, 207, 5.0),\n",
              " (6, 209, 4.0),\n",
              " (6, 210, 5.0),\n",
              " (6, 211, 1.0),\n",
              " (6, 212, 3.0),\n",
              " (6, 213, 5.0),\n",
              " (6, 214, 4.0),\n",
              " (6, 215, 4.0),\n",
              " (6, 216, 4.0),\n",
              " (6, 218, 1.0),\n",
              " (6, 222, 5.0),\n",
              " (6, 225, 5.0),\n",
              " (6, 226, 3.0),\n",
              " (6, 227, 4.0),\n",
              " (6, 228, 3.0),\n",
              " (6, 229, 3.0),\n",
              " (6, 230, 3.0),\n",
              " (6, 231, 3.0),\n",
              " (6, 233, 5.0),\n",
              " (6, 236, 5.0),\n",
              " (6, 237, 5.0),\n",
              " (6, 240, 4.0),\n",
              " (6, 257, 4.0),\n",
              " (6, 258, 3.0),\n",
              " (6, 259, 1.0),\n",
              " (6, 263, 4.0),\n",
              " (6, 264, 5.0),\n",
              " (6, 265, 4.0),\n",
              " (6, 267, 3.0),\n",
              " (6, 268, 3.0),\n",
              " (6, 272, 3.0),\n",
              " (6, 274, 4.0),\n",
              " (6, 280, 3.0),\n",
              " (6, 284, 5.0),\n",
              " (6, 285, 4.0),\n",
              " (6, 287, 4.0),\n",
              " (6, 293, 1.0),\n",
              " (6, 299, 4.0),\n",
              " (6, 306, 5.0),\n",
              " (6, 308, 3.0),\n",
              " (6, 316, 4.0),\n",
              " (6, 317, 5.0),\n",
              " (6, 323, 1.0),\n",
              " (6, 333, 5.0),\n",
              " (6, 340, 3.0),\n",
              " (6, 355, 4.0),\n",
              " (6, 356, 5.0),\n",
              " (6, 364, 4.0),\n",
              " (6, 366, 5.0),\n",
              " (6, 377, 5.0),\n",
              " (6, 378, 4.0),\n",
              " (6, 379, 4.0),\n",
              " (6, 381, 4.0),\n",
              " (6, 383, 3.0),\n",
              " (6, 384, 5.0),\n",
              " (6, 385, 4.0),\n",
              " (6, 386, 3.0),\n",
              " (6, 388, 4.0),\n",
              " (6, 390, 3.0),\n",
              " (6, 392, 4.0),\n",
              " (6, 395, 4.0),\n",
              " (6, 398, 4.0),\n",
              " (6, 400, 4.0),\n",
              " (6, 401, 5.0),\n",
              " (6, 402, 4.0),\n",
              " (6, 403, 5.0),\n",
              " (6, 404, 3.0),\n",
              " (6, 414, 2.0),\n",
              " (6, 415, 5.0),\n",
              " (6, 416, 3.0),\n",
              " (6, 417, 4.0),\n",
              " (6, 418, 3.0),\n",
              " (6, 419, 5.0),\n",
              " (6, 420, 3.0),\n",
              " (6, 422, 5.0),\n",
              " (6, 426, 5.0),\n",
              " (6, 427, 5.0),\n",
              " (6, 428, 5.0),\n",
              " (6, 429, 3.0),\n",
              " (6, 430, 4.0),\n",
              " (6, 431, 4.0),\n",
              " (6, 432, 5.0),\n",
              " (6, 433, 4.0),\n",
              " (6, 434, 5.0),\n",
              " (6, 435, 5.0),\n",
              " (6, 439, 1.0),\n",
              " (6, 440, 2.0),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(real_mat, P, Q, non_zeros):\n",
        "  # real_df = 실제 유저 아이템 행렬\n",
        "  # P, Q = 잠재요인, user와 item으로 분해된 잠재행렬, 이걸로 예측 행렬 생성\n",
        "  # non_null = real_df 내 null값 아니었던 것(real_df 만으로 함수 내 해결할 수 있을것으로 보이나, 저장해서 반복 계산 시 효율성 재고)\n",
        "  error = 0\n",
        "  pred_mat = np.dot(P, Q.T)\n",
        "  # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "  user_non_zero_index = [non_zero[0] for non_zero in non_zeros]\n",
        "  item_non_zero_index = [non_zero[1] for non_zero in non_zeros]\n",
        "  real_mat_non_zero = real_mat[user_non_zero_index, item_non_zero_index]\n",
        "  pred_mat_non_zero = pred_mat[user_non_zero_index, item_non_zero_index]\n",
        "\n",
        "  mse = mean_squared_error(real_mat_non_zero, pred_mat_non_zero)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "UZNfhGz0vrOC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_rmse(real_mat, P,Q, non_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjtJKG8eEKcC",
        "outputId": "f5dba0be-7af8-4aaa-e643-19e85f29172b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7060615755099544"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**비용 함수 생략 잠재 행렬(P, Q) 내 벡터(Pu, Qi) 업데이트 식**  \n",
        "  \n",
        "* Rui = 실제 행렬의 (u, i) 값  \n",
        "* R^ui = 예측 행렬의 (u, i) 값  \n",
        "* Eui = (u, i)위치의 실제행렬 값 예측행렬 값 차이 \n",
        "\n",
        "  * $e_{ui}=r_{ui}-p_uq_i^T$\n",
        "* Gradient\n",
        "  * $\\frac {\\partial L}{\\partial p_u} = \\frac {\\partial(r_{ui}-p_uq_i^T)^2}{\\partial p_u} + \\frac {\\partial\\lambda||p_u||^2_2}{\\partial p_u} = -2(r_{ui}-p_uq_i^T)q_i+2\\lambda p_u = -2(e_{ui}q_i-\\lambda p_u)$\n",
        "    * 기존 LOSS에서 $p_u$에 대해 편미분을 진행해 필요없는 $q_i$항을 모두 지우고 계산하면 $-2(e_{ui}q_i-\\lambda p_u)$가 남게 됨.\n",
        "  * Gradient 반대로 $p_u, q_i$ 업데이트\n",
        "    * $p_u ← p_u +\\eta \\cdot(e_{ui}q_i - \\lambda p_u)$\n",
        "    * $q_i ← q_i +\\eta \\cdot(e_{ui}p_u - \\lambda q_i)$\n",
        "  \n",
        "* Pu(new) = Pu + 학습률 * (Eui * Qi - lambda(L2 정규화 계수) * Pu)  \n",
        "* Qi(new) = Qi + 학습률 * (Eui * Pu - lambda(L2 정규화 계수) * Qi)\n"
      ],
      "metadata": {
        "id": "371acnId1GCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iteration = 2000\n",
        "learning_rate = 0.001\n",
        "lmbda = 0.01"
      ],
      "metadata": {
        "id": "R7HxbXnM00m2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(iteration):\n",
        "  for i, j, Rij in non_zeros:\n",
        "    # 실제 값과 예측 값의 차이인 오류 값 구함\n",
        "    Eij = Rij - np.dot(P[i, :], Q[j, :].T)\n",
        "    # 벡터 업데이트 :Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i, :] = P[i, :] + learning_rate *(Eij* Q[j, :] - lmbda* P[i, :])\n",
        "    Q[j, :] = Q[j, :] + learning_rate *(Eij* P[i, :] - lmbda* Q[j, :])\n",
        "  rmse = get_rmse(real_mat, P, Q, non_zeros)\n",
        "  if (iter+1) % 10 == 0:\n",
        "    print('iteration num : ', iter+1, \" rmse : \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fdJlOoFx48a6",
        "outputId": "ff697dcc-7d99-4e67-8550-100bf18f8d0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration num :  10  rmse :  1.7554530700155224\n",
            "iteration num :  20  rmse :  1.079547313608221\n",
            "iteration num :  30  rmse :  0.9772009392521711\n",
            "iteration num :  40  rmse :  0.9423830292652029\n",
            "iteration num :  50  rmse :  0.923054903690508\n",
            "iteration num :  60  rmse :  0.9087425845002808\n",
            "iteration num :  70  rmse :  0.8967946490366422\n",
            "iteration num :  80  rmse :  0.8865177108755139\n",
            "iteration num :  90  rmse :  0.8775954095775489\n",
            "iteration num :  100  rmse :  0.8697653141003603\n",
            "iteration num :  110  rmse :  0.86282184648358\n",
            "iteration num :  120  rmse :  0.8566197152110971\n",
            "iteration num :  130  rmse :  0.851057045541995\n",
            "iteration num :  140  rmse :  0.8460580933643697\n",
            "iteration num :  150  rmse :  0.8415617138768727\n",
            "iteration num :  160  rmse :  0.8375151242732989\n",
            "iteration num :  170  rmse :  0.83387102905159\n",
            "iteration num :  180  rmse :  0.8305864519363927\n",
            "iteration num :  190  rmse :  0.8276222839910465\n",
            "iteration num :  200  rmse :  0.8249430733695061\n",
            "iteration num :  210  rmse :  0.8225168654635651\n",
            "iteration num :  220  rmse :  0.82031503020717\n",
            "iteration num :  230  rmse :  0.8183120632675892\n",
            "iteration num :  240  rmse :  0.8164853643056452\n",
            "iteration num :  250  rmse :  0.8148149995185887\n",
            "iteration num :  260  rmse :  0.8132834560315346\n",
            "iteration num :  270  rmse :  0.8118753952890241\n",
            "iteration num :  280  rmse :  0.8105774119774247\n",
            "iteration num :  290  rmse :  0.8093778041095473\n",
            "iteration num :  300  rmse :  0.8082663586888901\n",
            "iteration num :  310  rmse :  0.8072341559603349\n",
            "iteration num :  320  rmse :  0.8062733938382138\n",
            "iteration num :  330  rmse :  0.8053772328516892\n",
            "iteration num :  340  rmse :  0.8045396609634429\n",
            "iteration num :  350  rmse :  0.8037553769314417\n",
            "iteration num :  360  rmse :  0.8030196904735087\n",
            "iteration num :  370  rmse :  0.8023284373107116\n",
            "iteration num :  380  rmse :  0.8016779071493223\n",
            "iteration num :  390  rmse :  0.8010647827568164\n",
            "iteration num :  400  rmse :  0.8004860884489802\n",
            "iteration num :  410  rmse :  0.799939146497969\n",
            "iteration num :  420  rmse :  0.7994215401709402\n",
            "iteration num :  430  rmse :  0.7989310823004068\n",
            "iteration num :  440  rmse :  0.7984657884621313\n",
            "iteration num :  450  rmse :  0.7980238539903172\n",
            "iteration num :  460  rmse :  0.7976036341922744\n",
            "iteration num :  470  rmse :  0.7972036272366729\n",
            "iteration num :  480  rmse :  0.796822459282917\n",
            "iteration num :  490  rmse :  0.7964588714964336\n",
            "iteration num :  500  rmse :  0.7961117086581562\n",
            "iteration num :  510  rmse :  0.7957799091283801\n",
            "iteration num :  520  rmse :  0.7954624959674614\n",
            "iteration num :  530  rmse :  0.795158569050183\n",
            "iteration num :  540  rmse :  0.7948672980384868\n",
            "iteration num :  550  rmse :  0.7945879160998314\n",
            "iteration num :  560  rmse :  0.7943197142767091\n",
            "iteration num :  570  rmse :  0.7940620364276595\n",
            "iteration num :  580  rmse :  0.793814274672128\n",
            "iteration num :  590  rmse :  0.7935758652813066\n",
            "iteration num :  600  rmse :  0.7933462849651106\n",
            "iteration num :  610  rmse :  0.793125047512046\n",
            "iteration num :  620  rmse :  0.79291170074423\n",
            "iteration num :  630  rmse :  0.7927058237544344\n",
            "iteration num :  640  rmse :  0.7925070243959478\n",
            "iteration num :  650  rmse :  0.7923149369994038\n",
            "iteration num :  660  rmse :  0.7921292202936376\n",
            "iteration num :  670  rmse :  0.7919495555101675\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6450787e1d76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEij\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEij\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration num : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" rmse : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-737f7e502bbb>\u001b[0m in \u001b[0;36mget_rmse\u001b[0;34m(real_mat, P, Q, non_zeros)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0muser_non_zero_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnon_zero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnon_zero\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_zeros\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mitem_non_zero_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnon_zero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnon_zero\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_zeros\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mreal_mat_non_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_non_zero_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_non_zero_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mpred_mat_non_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_non_zero_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_non_zero_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이후 내용은 추천시스템.  \n",
        "test train 나눠서 검증이 아니라 최대한 오차를 낮춘 다음 유저가 안 본 영화 중 예측 평점 높은 순대로 추천하는 시스템.  \n",
        "그렇다면 과적합 문제가 발생하지 않을까?  \n"
      ],
      "metadata": {
        "id": "MR__DdtPT8tk"
      }
    }
  ]
}